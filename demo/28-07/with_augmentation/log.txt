[07/26 15:45:58] detectron2 INFO: Rank of current process: 0. World size: 1
[07/26 15:46:00] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  2 2021, 10:49:15) [GCC 9.4.0]
numpy                   1.18.5
detectron2              0.4.1 @/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.1
torchvision             0.10.0+cu111 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20210722
iopath                  0.1.8
cv2                     4.5.3
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/26 15:46:00] detectron2 INFO: Command line arguments: Namespace(config_file='train.yaml', dist_url='tcp://127.0.0.1:49791', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/26 15:46:00] detectron2 INFO: Contents of args.config_file=train.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mconfigs/Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mpre-trained/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m101
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m35.55[39m,[38;5;15m [39m[38;5;15m35.55[39m,[38;5;15m [39m[38;5;15m35.55[39m]
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.02
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m(100,)
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m7500[38;5;15m   [39m[38;5;242m#Number of image to train * number of epochs desired[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("for_detectron_synth_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("for_detectron_synth_val",)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39moutput/with_augmentation
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1500

[07/26 15:46:00] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39mfor_detectron_synth_val
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39mfor_detectron_synth_train
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.9
[38;5;15m    [39m-[38;5;15m [39m0.9
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mrelative_range
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mpolygon
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m1333
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m1333
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m800
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m640
[38;5;15m  [39m-[38;5;15m [39m672
[38;5;15m  [39m-[38;5;15m [39m704
[38;5;15m  [39m-[38;5;15m [39m736
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m800
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m64
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m128
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mbuild_resnet_fpn_backbone
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mGeneralizedRCNN
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m35.55
[38;5;15m  [39m-[38;5;15m [39m35.55
[38;5;15m  [39m-[38;5;15m [39m35.55
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m101
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mFastRCNNConvFCHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mStandardROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mSemSegFPNHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m54
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mpre-trained/R-101.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39moutput/with_augmentation
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.02
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mvalue
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupMultiStepLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m7500
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m0.001
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.0001
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m0.0001
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4000
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m400
[38;5;15m    [39m-[38;5;15m [39m500
[38;5;15m    [39m-[38;5;15m [39m600
[38;5;15m    [39m-[38;5;15m [39m700
[38;5;15m    [39m-[38;5;15m [39m800
[38;5;15m    [39m-[38;5;15m [39m900
[38;5;15m    [39m-[38;5;15m [39m1000
[38;5;15m    [39m-[38;5;15m [39m1100
[38;5;15m    [39m-[38;5;15m [39m1200
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[07/26 15:46:00] detectron2 INFO: Full config saved to output/with_augmentation/config.yaml
[07/26 15:46:00] d2.utils.env INFO: Using a generated random seed 424699
[07/26 15:46:32] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/26 15:46:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pre-trained/R-101.pkl ...
[07/26 15:46:32] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[07/26 15:46:32] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[07/26 15:46:32] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[07/26 15:46:32] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[07/26 15:46:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomContrast(intensity_min=0.9, intensity_max=1.1)]
[07/26 15:47:29] d2.data.build INFO: Removed 0 images with no usable annotations. 750 images left.
[07/26 15:47:29] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   Femur    | 750          |   Tibia    | 0            |   Guide    | 553          |
|            |              |            |              |            |              |
|   total    | 1303         |            |              |            |              |[0m
[07/26 15:47:29] d2.data.build INFO: Using training sampler TrainingSampler
[07/26 15:47:29] d2.data.common INFO: Serializing 750 elements to byte tensors and concatenating them all ...
[07/26 15:47:30] d2.data.common INFO: Serialized dataset takes 7.52 MiB
[07/26 15:47:30] detectron2 INFO: Starting training from iteration 0
[07/26 15:47:43] d2.utils.events INFO:  iter: 19  total_loss: 1.962  loss_cls: 0.5959  loss_box_reg: 0.006849  loss_mask: 0.6851  loss_rpn_cls: 0.6461  loss_rpn_loc: 0.02343  lr: 5.762e-05  max_mem: 5431M
[07/26 15:47:56] d2.utils.events INFO:  eta: 1:20:11  iter: 39  total_loss: 1.276  loss_cls: 0.19  loss_box_reg: 0.0208  loss_mask: 0.6462  loss_rpn_cls: 0.4137  loss_rpn_loc: 0.02561  lr: 9.722e-05  max_mem: 5431M
[07/26 15:48:09] d2.utils.events INFO:  eta: 1:21:19  iter: 59  total_loss: 1.075  loss_cls: 0.1898  loss_box_reg: 0.05145  loss_mask: 0.6674  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.01949  lr: 0.00013682  max_mem: 5431M
[07/26 15:48:23] d2.utils.events INFO:  eta: 1:21:32  iter: 79  total_loss: 0.924  loss_cls: 0.1183  loss_box_reg: 0.04906  loss_mask: 0.665  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.01612  lr: 0.00017642  max_mem: 5431M
[07/26 15:48:36] d2.utils.events INFO:  eta: 1:22:14  iter: 99  total_loss: 0.9344  loss_cls: 0.1476  loss_box_reg: 0.06339  loss_mask: 0.6407  loss_rpn_cls: 0.06153  loss_rpn_loc: 0.017  lr: 0.00021602  max_mem: 5431M
[07/26 15:48:49] d2.utils.events INFO:  eta: 1:23:30  iter: 119  total_loss: 0.8968  loss_cls: 0.09537  loss_box_reg: 0.08254  loss_mask: 0.6504  loss_rpn_cls: 0.04943  loss_rpn_loc: 0.01546  lr: 0.00025562  max_mem: 5685M
[07/26 15:49:03] d2.utils.events INFO:  eta: 1:25:00  iter: 139  total_loss: 0.9142  loss_cls: 0.108  loss_box_reg: 0.1289  loss_mask: 0.6258  loss_rpn_cls: 0.03569  loss_rpn_loc: 0.01489  lr: 0.00029522  max_mem: 5818M
[07/26 15:49:17] d2.utils.events INFO:  eta: 1:26:35  iter: 159  total_loss: 0.9217  loss_cls: 0.1125  loss_box_reg: 0.1476  loss_mask: 0.608  loss_rpn_cls: 0.03836  loss_rpn_loc: 0.01563  lr: 0.00033482  max_mem: 5961M
[07/26 15:49:32] d2.utils.events INFO:  eta: 1:26:18  iter: 179  total_loss: 0.8587  loss_cls: 0.1169  loss_box_reg: 0.1416  loss_mask: 0.5595  loss_rpn_cls: 0.03553  loss_rpn_loc: 0.01515  lr: 0.00037442  max_mem: 5961M
[07/26 15:49:46] d2.utils.events INFO:  eta: 1:28:50  iter: 199  total_loss: 0.9076  loss_cls: 0.1471  loss_box_reg: 0.1906  loss_mask: 0.5253  loss_rpn_cls: 0.02969  loss_rpn_loc: 0.0162  lr: 0.00041402  max_mem: 6086M
[07/26 15:50:01] d2.utils.events INFO:  eta: 1:27:39  iter: 219  total_loss: 0.8705  loss_cls: 0.1283  loss_box_reg: 0.1712  loss_mask: 0.5204  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.01548  lr: 0.00045362  max_mem: 6109M
[07/26 15:50:15] d2.utils.events INFO:  eta: 1:27:42  iter: 239  total_loss: 0.8184  loss_cls: 0.1254  loss_box_reg: 0.1629  loss_mask: 0.4872  loss_rpn_cls: 0.02443  loss_rpn_loc: 0.01492  lr: 0.00049322  max_mem: 6109M
[07/26 15:50:30] d2.utils.events INFO:  eta: 1:28:27  iter: 259  total_loss: 0.8073  loss_cls: 0.1287  loss_box_reg: 0.1801  loss_mask: 0.4627  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.01474  lr: 0.00053282  max_mem: 6223M
[07/26 15:50:45] d2.utils.events INFO:  eta: 1:29:02  iter: 279  total_loss: 0.7591  loss_cls: 0.1182  loss_box_reg: 0.1681  loss_mask: 0.4413  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.01312  lr: 0.00057242  max_mem: 6284M
[07/26 15:51:00] d2.utils.events INFO:  eta: 1:30:10  iter: 299  total_loss: 0.7692  loss_cls: 0.1226  loss_box_reg: 0.1882  loss_mask: 0.4217  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.01397  lr: 0.00061202  max_mem: 6441M
[07/26 15:51:15] d2.utils.events INFO:  eta: 1:29:49  iter: 319  total_loss: 0.7327  loss_cls: 0.117  loss_box_reg: 0.1861  loss_mask: 0.3913  loss_rpn_cls: 0.01762  loss_rpn_loc: 0.01438  lr: 0.00065162  max_mem: 6441M
[07/26 15:51:30] d2.utils.events INFO:  eta: 1:28:55  iter: 339  total_loss: 0.8198  loss_cls: 0.134  loss_box_reg: 0.1693  loss_mask: 0.4453  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.0151  lr: 0.00069122  max_mem: 6441M
[07/26 15:51:45] d2.utils.events INFO:  eta: 1:29:39  iter: 359  total_loss: 0.7309  loss_cls: 0.125  loss_box_reg: 0.1893  loss_mask: 0.3984  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01337  lr: 0.00073082  max_mem: 6446M
[07/26 15:52:00] d2.utils.events INFO:  eta: 1:30:10  iter: 379  total_loss: 0.6828  loss_cls: 0.1181  loss_box_reg: 0.1772  loss_mask: 0.3502  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.01398  lr: 0.00077042  max_mem: 6450M
[07/26 15:52:15] d2.utils.events INFO:  eta: 1:30:55  iter: 399  total_loss: 0.6569  loss_cls: 0.1179  loss_box_reg: 0.1933  loss_mask: 0.3257  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.01358  lr: 0.00081002  max_mem: 6682M
[07/26 15:52:31] d2.utils.events INFO:  eta: 1:30:51  iter: 419  total_loss: 0.661  loss_cls: 0.1199  loss_box_reg: 0.197  loss_mask: 0.3218  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.01213  lr: 0.00084962  max_mem: 6682M
[07/26 15:52:46] d2.utils.events INFO:  eta: 1:30:33  iter: 439  total_loss: 0.655  loss_cls: 0.1172  loss_box_reg: 0.1924  loss_mask: 0.3389  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.01145  lr: 0.00088922  max_mem: 6682M
[07/26 15:53:01] d2.utils.events INFO:  eta: 1:29:35  iter: 459  total_loss: 0.6311  loss_cls: 0.1145  loss_box_reg: 0.1844  loss_mask: 0.3156  loss_rpn_cls: 0.008836  loss_rpn_loc: 0.01238  lr: 0.00092882  max_mem: 6682M
[07/26 15:53:17] d2.utils.events INFO:  eta: 1:29:46  iter: 479  total_loss: 0.5734  loss_cls: 0.1016  loss_box_reg: 0.1659  loss_mask: 0.2843  loss_rpn_cls: 0.008074  loss_rpn_loc: 0.01107  lr: 0.00096842  max_mem: 6682M
[07/26 15:53:32] d2.utils.events INFO:  eta: 1:30:08  iter: 499  total_loss: 0.5945  loss_cls: 0.103  loss_box_reg: 0.1831  loss_mask: 0.2819  loss_rpn_cls: 0.008781  loss_rpn_loc: 0.01127  lr: 0.001008  max_mem: 6725M
[07/26 15:53:48] d2.utils.events INFO:  eta: 1:30:48  iter: 519  total_loss: 0.5833  loss_cls: 0.1071  loss_box_reg: 0.1755  loss_mask: 0.2703  loss_rpn_cls: 0.008745  loss_rpn_loc: 0.01166  lr: 0.0010476  max_mem: 6917M
[07/26 15:54:03] d2.utils.events INFO:  eta: 1:30:01  iter: 539  total_loss: 0.5377  loss_cls: 0.09153  loss_box_reg: 0.1724  loss_mask: 0.251  loss_rpn_cls: 0.008241  loss_rpn_loc: 0.01092  lr: 0.0010872  max_mem: 6917M
[07/26 15:54:19] d2.utils.events INFO:  eta: 1:29:40  iter: 559  total_loss: 0.5451  loss_cls: 0.09676  loss_box_reg: 0.1669  loss_mask: 0.2603  loss_rpn_cls: 0.007559  loss_rpn_loc: 0.01098  lr: 0.0011268  max_mem: 6917M
[07/26 15:54:34] d2.utils.events INFO:  eta: 1:30:21  iter: 579  total_loss: 0.5639  loss_cls: 0.1033  loss_box_reg: 0.1756  loss_mask: 0.265  loss_rpn_cls: 0.005811  loss_rpn_loc: 0.01206  lr: 0.0011664  max_mem: 6917M
[07/26 15:54:50] d2.utils.events INFO:  eta: 1:29:50  iter: 599  total_loss: 0.528  loss_cls: 0.09042  loss_box_reg: 0.1676  loss_mask: 0.2502  loss_rpn_cls: 0.0057  loss_rpn_loc: 0.009392  lr: 0.001206  max_mem: 7051M
[07/26 15:55:05] d2.utils.events INFO:  eta: 1:28:17  iter: 619  total_loss: 0.5159  loss_cls: 0.09176  loss_box_reg: 0.1647  loss_mask: 0.2446  loss_rpn_cls: 0.006147  loss_rpn_loc: 0.009835  lr: 0.0012456  max_mem: 7051M
[07/26 15:55:21] d2.utils.events INFO:  eta: 1:29:21  iter: 639  total_loss: 0.4918  loss_cls: 0.0843  loss_box_reg: 0.1498  loss_mask: 0.2353  loss_rpn_cls: 0.006591  loss_rpn_loc: 0.009653  lr: 0.0012852  max_mem: 7051M
[07/26 15:55:37] d2.utils.events INFO:  eta: 1:29:58  iter: 659  total_loss: 0.5223  loss_cls: 0.09752  loss_box_reg: 0.1892  loss_mask: 0.2365  loss_rpn_cls: 0.004975  loss_rpn_loc: 0.01028  lr: 0.0013248  max_mem: 7051M
[07/26 15:55:52] d2.utils.events INFO:  eta: 1:28:38  iter: 679  total_loss: 0.473  loss_cls: 0.08228  loss_box_reg: 0.1593  loss_mask: 0.2271  loss_rpn_cls: 0.00489  loss_rpn_loc: 0.009288  lr: 0.0013644  max_mem: 7051M
[07/26 15:56:08] d2.utils.events INFO:  eta: 1:27:51  iter: 699  total_loss: 0.4648  loss_cls: 0.08217  loss_box_reg: 0.1482  loss_mask: 0.2244  loss_rpn_cls: 0.005214  loss_rpn_loc: 0.008983  lr: 0.001404  max_mem: 7051M
[07/26 15:56:23] d2.utils.events INFO:  eta: 1:27:13  iter: 719  total_loss: 0.4542  loss_cls: 0.07763  loss_box_reg: 0.1517  loss_mask: 0.2178  loss_rpn_cls: 0.00486  loss_rpn_loc: 0.00912  lr: 0.0014436  max_mem: 7051M
[07/26 15:56:39] d2.utils.events INFO:  eta: 1:28:28  iter: 739  total_loss: 0.4537  loss_cls: 0.08223  loss_box_reg: 0.1602  loss_mask: 0.2062  loss_rpn_cls: 0.003611  loss_rpn_loc: 0.008348  lr: 0.0014832  max_mem: 7052M
[07/26 15:56:55] d2.utils.events INFO:  eta: 1:27:08  iter: 759  total_loss: 0.4759  loss_cls: 0.08267  loss_box_reg: 0.1599  loss_mask: 0.2149  loss_rpn_cls: 0.004704  loss_rpn_loc: 0.00939  lr: 0.0015228  max_mem: 7052M
[07/26 15:57:10] d2.utils.events INFO:  eta: 1:27:17  iter: 779  total_loss: 0.4823  loss_cls: 0.08255  loss_box_reg: 0.1474  loss_mask: 0.2199  loss_rpn_cls: 0.004956  loss_rpn_loc: 0.01074  lr: 0.0015624  max_mem: 7052M
[07/26 15:57:26] d2.utils.events INFO:  eta: 1:26:19  iter: 799  total_loss: 0.4255  loss_cls: 0.07137  loss_box_reg: 0.1422  loss_mask: 0.2071  loss_rpn_cls: 0.003699  loss_rpn_loc: 0.009425  lr: 0.001602  max_mem: 7052M
[07/26 15:57:41] d2.utils.events INFO:  eta: 1:26:38  iter: 819  total_loss: 0.4187  loss_cls: 0.07195  loss_box_reg: 0.1447  loss_mask: 0.1857  loss_rpn_cls: 0.004913  loss_rpn_loc: 0.008751  lr: 0.0016416  max_mem: 7052M
[07/26 15:57:57] d2.utils.events INFO:  eta: 1:26:31  iter: 839  total_loss: 0.4507  loss_cls: 0.07777  loss_box_reg: 0.1465  loss_mask: 0.2151  loss_rpn_cls: 0.005016  loss_rpn_loc: 0.00931  lr: 0.0016812  max_mem: 7052M
[07/26 15:58:12] d2.utils.events INFO:  eta: 1:24:34  iter: 859  total_loss: 0.4004  loss_cls: 0.06712  loss_box_reg: 0.1329  loss_mask: 0.1887  loss_rpn_cls: 0.004593  loss_rpn_loc: 0.00822  lr: 0.0017208  max_mem: 7052M
[07/26 15:58:28] d2.utils.events INFO:  eta: 1:25:32  iter: 879  total_loss: 0.3966  loss_cls: 0.06957  loss_box_reg: 0.1327  loss_mask: 0.1713  loss_rpn_cls: 0.004522  loss_rpn_loc: 0.008161  lr: 0.0017604  max_mem: 7052M
[07/26 15:58:43] d2.utils.events INFO:  eta: 1:26:02  iter: 899  total_loss: 0.4048  loss_cls: 0.06694  loss_box_reg: 0.1333  loss_mask: 0.1805  loss_rpn_cls: 0.00376  loss_rpn_loc: 0.008846  lr: 0.0018  max_mem: 7052M
[07/26 15:58:59] d2.utils.events INFO:  eta: 1:24:37  iter: 919  total_loss: 0.4276  loss_cls: 0.07007  loss_box_reg: 0.1388  loss_mask: 0.2016  loss_rpn_cls: 0.004157  loss_rpn_loc: 0.008605  lr: 0.0018396  max_mem: 7052M
[07/26 15:59:14] d2.utils.events INFO:  eta: 1:24:27  iter: 939  total_loss: 0.4269  loss_cls: 0.07225  loss_box_reg: 0.1415  loss_mask: 0.1997  loss_rpn_cls: 0.003883  loss_rpn_loc: 0.009501  lr: 0.0018792  max_mem: 7052M
[07/26 15:59:29] d2.utils.events INFO:  eta: 1:23:43  iter: 959  total_loss: 0.3807  loss_cls: 0.06667  loss_box_reg: 0.1251  loss_mask: 0.1752  loss_rpn_cls: 0.003726  loss_rpn_loc: 0.007755  lr: 0.0019188  max_mem: 7052M
[07/26 15:59:45] d2.utils.events INFO:  eta: 1:26:05  iter: 979  total_loss: 0.3813  loss_cls: 0.06866  loss_box_reg: 0.1368  loss_mask: 0.169  loss_rpn_cls: 0.003103  loss_rpn_loc: 0.008267  lr: 0.0019584  max_mem: 7127M
[07/26 16:00:01] d2.utils.events INFO:  eta: 1:24:11  iter: 999  total_loss: 0.407  loss_cls: 0.06655  loss_box_reg: 0.1381  loss_mask: 0.1816  loss_rpn_cls: 0.003501  loss_rpn_loc: 0.009079  lr: 0.001998  max_mem: 7127M
[07/26 16:00:16] d2.utils.events INFO:  eta: 1:23:21  iter: 1019  total_loss: 0.4079  loss_cls: 0.06505  loss_box_reg: 0.1369  loss_mask: 0.1843  loss_rpn_cls: 0.004301  loss_rpn_loc: 0.007992  lr: 0.002  max_mem: 7127M
[07/26 16:00:32] d2.utils.events INFO:  eta: 1:23:04  iter: 1039  total_loss: 0.3756  loss_cls: 0.06129  loss_box_reg: 0.1186  loss_mask: 0.1836  loss_rpn_cls: 0.003186  loss_rpn_loc: 0.007996  lr: 0.002  max_mem: 7127M
[07/26 16:00:47] d2.utils.events INFO:  eta: 1:22:30  iter: 1059  total_loss: 0.3686  loss_cls: 0.06074  loss_box_reg: 0.1221  loss_mask: 0.1678  loss_rpn_cls: 0.003063  loss_rpn_loc: 0.007496  lr: 0.002  max_mem: 7127M
[07/26 16:01:03] d2.utils.events INFO:  eta: 1:23:02  iter: 1079  total_loss: 0.3568  loss_cls: 0.05971  loss_box_reg: 0.1216  loss_mask: 0.1643  loss_rpn_cls: 0.003023  loss_rpn_loc: 0.007738  lr: 0.002  max_mem: 7127M
[07/26 16:01:18] d2.utils.events INFO:  eta: 1:22:20  iter: 1099  total_loss: 0.3791  loss_cls: 0.06313  loss_box_reg: 0.1272  loss_mask: 0.1751  loss_rpn_cls: 0.00332  loss_rpn_loc: 0.007518  lr: 0.002  max_mem: 7127M
[07/26 16:01:33] d2.utils.events INFO:  eta: 1:21:27  iter: 1119  total_loss: 0.3482  loss_cls: 0.05695  loss_box_reg: 0.1162  loss_mask: 0.1573  loss_rpn_cls: 0.002635  loss_rpn_loc: 0.006854  lr: 0.002  max_mem: 7127M
[07/26 16:01:49] d2.utils.events INFO:  eta: 1:21:31  iter: 1139  total_loss: 0.3384  loss_cls: 0.05423  loss_box_reg: 0.1137  loss_mask: 0.1626  loss_rpn_cls: 0.002244  loss_rpn_loc: 0.007174  lr: 0.002  max_mem: 7127M
[07/26 16:02:04] d2.utils.events INFO:  eta: 1:20:42  iter: 1159  total_loss: 0.3642  loss_cls: 0.05602  loss_box_reg: 0.1209  loss_mask: 0.1783  loss_rpn_cls: 0.0025  loss_rpn_loc: 0.007224  lr: 0.002  max_mem: 7127M
[07/26 16:02:19] d2.utils.events INFO:  eta: 1:20:48  iter: 1179  total_loss: 0.3281  loss_cls: 0.05429  loss_box_reg: 0.111  loss_mask: 0.1573  loss_rpn_cls: 0.00242  loss_rpn_loc: 0.007215  lr: 0.002  max_mem: 7127M
[07/26 16:02:35] d2.utils.events INFO:  eta: 1:20:44  iter: 1199  total_loss: 0.3268  loss_cls: 0.05132  loss_box_reg: 0.1107  loss_mask: 0.1593  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.006797  lr: 0.002  max_mem: 7127M
[07/26 16:02:50] d2.utils.events INFO:  eta: 1:21:26  iter: 1219  total_loss: 0.3293  loss_cls: 0.05274  loss_box_reg: 0.1056  loss_mask: 0.1533  loss_rpn_cls: 0.002216  loss_rpn_loc: 0.007848  lr: 0.002  max_mem: 7127M
[07/26 16:03:06] d2.utils.events INFO:  eta: 1:20:21  iter: 1239  total_loss: 0.3049  loss_cls: 0.04824  loss_box_reg: 0.1025  loss_mask: 0.1445  loss_rpn_cls: 0.002802  loss_rpn_loc: 0.006719  lr: 0.002  max_mem: 7127M
[07/26 16:03:21] d2.utils.events INFO:  eta: 1:21:32  iter: 1259  total_loss: 0.316  loss_cls: 0.05091  loss_box_reg: 0.1039  loss_mask: 0.1465  loss_rpn_cls: 0.001901  loss_rpn_loc: 0.00721  lr: 0.002  max_mem: 7127M
[07/26 16:03:37] d2.utils.events INFO:  eta: 1:19:23  iter: 1279  total_loss: 0.3117  loss_cls: 0.05001  loss_box_reg: 0.1042  loss_mask: 0.138  loss_rpn_cls: 0.002183  loss_rpn_loc: 0.005963  lr: 0.002  max_mem: 7127M
[07/26 16:03:52] d2.utils.events INFO:  eta: 1:20:36  iter: 1299  total_loss: 0.3547  loss_cls: 0.05823  loss_box_reg: 0.1254  loss_mask: 0.1567  loss_rpn_cls: 0.002268  loss_rpn_loc: 0.00731  lr: 0.002  max_mem: 7127M
[07/26 16:04:08] d2.utils.events INFO:  eta: 1:18:34  iter: 1319  total_loss: 0.3668  loss_cls: 0.05935  loss_box_reg: 0.1154  loss_mask: 0.1772  loss_rpn_cls: 0.003491  loss_rpn_loc: 0.00693  lr: 0.002  max_mem: 7127M
[07/26 16:04:23] d2.utils.events INFO:  eta: 1:18:38  iter: 1339  total_loss: 0.2891  loss_cls: 0.04448  loss_box_reg: 0.1011  loss_mask: 0.1402  loss_rpn_cls: 0.001665  loss_rpn_loc: 0.007318  lr: 0.002  max_mem: 7127M
[07/26 16:04:38] d2.utils.events INFO:  eta: 1:19:24  iter: 1359  total_loss: 0.3011  loss_cls: 0.04814  loss_box_reg: 0.096  loss_mask: 0.14  loss_rpn_cls: 0.002287  loss_rpn_loc: 0.006024  lr: 0.002  max_mem: 7127M
[07/26 16:04:54] d2.utils.events INFO:  eta: 1:18:17  iter: 1379  total_loss: 0.2867  loss_cls: 0.04311  loss_box_reg: 0.09652  loss_mask: 0.1378  loss_rpn_cls: 0.002312  loss_rpn_loc: 0.006771  lr: 0.002  max_mem: 7127M
[07/26 16:05:09] d2.utils.events INFO:  eta: 1:19:57  iter: 1399  total_loss: 0.3117  loss_cls: 0.05327  loss_box_reg: 0.1126  loss_mask: 0.1416  loss_rpn_cls: 0.001985  loss_rpn_loc: 0.006377  lr: 0.002  max_mem: 7127M
[07/26 16:05:25] d2.utils.events INFO:  eta: 1:18:15  iter: 1419  total_loss: 0.2734  loss_cls: 0.04284  loss_box_reg: 0.09781  loss_mask: 0.1261  loss_rpn_cls: 0.001524  loss_rpn_loc: 0.006262  lr: 0.002  max_mem: 7127M
[07/26 16:05:40] d2.utils.events INFO:  eta: 1:17:54  iter: 1439  total_loss: 0.2955  loss_cls: 0.04703  loss_box_reg: 0.09882  loss_mask: 0.1441  loss_rpn_cls: 0.001668  loss_rpn_loc: 0.005731  lr: 0.002  max_mem: 7127M
[07/26 16:05:56] d2.utils.events INFO:  eta: 1:17:46  iter: 1459  total_loss: 0.293  loss_cls: 0.04678  loss_box_reg: 0.0971  loss_mask: 0.1368  loss_rpn_cls: 0.001735  loss_rpn_loc: 0.006464  lr: 0.002  max_mem: 7127M
[07/26 16:06:11] d2.utils.events INFO:  eta: 1:17:10  iter: 1479  total_loss: 0.3044  loss_cls: 0.04417  loss_box_reg: 0.09711  loss_mask: 0.1447  loss_rpn_cls: 0.001705  loss_rpn_loc: 0.00672  lr: 0.002  max_mem: 7127M
[07/26 16:06:27] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   Femur    | 45           |   Tibia    | 0            |   Guide    | 48           |
|            |              |            |              |            |              |
|   total    | 93           |            |              |            |              |[0m
[07/26 16:06:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/26 16:06:27] d2.data.common INFO: Serializing 45 elements to byte tensors and concatenating them all ...
[07/26 16:06:27] d2.data.common INFO: Serialized dataset takes 0.06 MiB
[07/26 16:06:27] d2.evaluation.coco_evaluation INFO: 'for_detectron_synth_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[07/26 16:06:27] d2.data.datasets.coco INFO: Converting annotations of dataset 'for_detectron_synth_val' to COCO format ...)
[07/26 16:06:27] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[07/26 16:06:27] d2.data.datasets.coco INFO: Conversion finished, #images: 45, #annotations: 93
[07/26 16:06:27] d2.data.datasets.coco INFO: Caching COCO format annotations at 'output/with_augmentation/inference/for_detectron_synth_val/for_detectron_synth_val_coco_format.json' ...
[07/26 16:06:27] d2.evaluation.evaluator INFO: Start inference on 45 batches
[07/26 16:06:28] d2.evaluation.evaluator INFO: Inference done 11/45. Dataloading: 0.0009 s/iter. Inference: 0.0608 s/iter. Eval: 0.0013 s/iter. Total: 0.0630 s/iter. ETA=0:00:02
[07/26 16:06:30] d2.evaluation.evaluator INFO: Total inference time: 0:00:02.532465 (0.063312 s / iter per device, on 1 devices)
[07/26 16:06:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.059582 s / iter per device, on 1 devices)
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Saving results to output/with_augmentation/inference/for_detectron_synth_val/coco_instances_results.json
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.754 | 9.411  | 6.530  | 0.000 | 5.907 | 0.000 |
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category   | AP     |
|:-----------|:------|:-----------|:-----|:-----------|:-------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 11.507 |
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:06:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.725 | 9.411  | 6.282  | 0.000 | 5.842 | 0.000 |
[07/26 16:06:30] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP   | category   | AP     |
|:-----------|:------|:-----------|:-----|:-----------|:-------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 11.451 |
[07/26 16:06:30] detectron2 INFO: Evaluation results for for_detectron_synth_val in csv format:
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: 5.7537,9.4111,6.5303,0.0000,5.9068,0.0000
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: Task: segm
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:06:30] d2.evaluation.testing INFO: copypaste: 5.7253,9.4111,6.2816,0.0000,5.8422,0.0000
[07/26 16:06:30] d2.utils.events INFO:  eta: 1:36:16  iter: 1499  total_loss: 0.3087  loss_cls: 0.04591  loss_box_reg: 0.1069  loss_mask: 0.1374  loss_rpn_cls: 0.002129  loss_rpn_loc: 0.006415  lr: 0.002  max_mem: 7127M
[07/26 16:06:46] d2.utils.events INFO:  eta: 1:15:50  iter: 1519  total_loss: 0.2844  loss_cls: 0.04379  loss_box_reg: 0.09524  loss_mask: 0.1369  loss_rpn_cls: 0.002051  loss_rpn_loc: 0.006197  lr: 0.002  max_mem: 7127M
[07/26 16:07:01] d2.utils.events INFO:  eta: 1:16:57  iter: 1539  total_loss: 0.2661  loss_cls: 0.04084  loss_box_reg: 0.08953  loss_mask: 0.1265  loss_rpn_cls: 0.001338  loss_rpn_loc: 0.006539  lr: 0.002  max_mem: 7127M
[07/26 16:07:17] d2.utils.events INFO:  eta: 1:16:39  iter: 1559  total_loss: 0.2708  loss_cls: 0.04239  loss_box_reg: 0.09697  loss_mask: 0.1242  loss_rpn_cls: 0.001772  loss_rpn_loc: 0.006344  lr: 0.002  max_mem: 7127M
[07/26 16:07:32] d2.utils.events INFO:  eta: 1:16:15  iter: 1579  total_loss: 0.2799  loss_cls: 0.04743  loss_box_reg: 0.09736  loss_mask: 0.1323  loss_rpn_cls: 0.002642  loss_rpn_loc: 0.006984  lr: 0.002  max_mem: 7127M
[07/26 16:07:48] d2.utils.events INFO:  eta: 1:16:26  iter: 1599  total_loss: 0.2737  loss_cls: 0.04326  loss_box_reg: 0.0928  loss_mask: 0.1233  loss_rpn_cls: 0.001985  loss_rpn_loc: 0.005493  lr: 0.002  max_mem: 7127M
[07/26 16:08:03] d2.utils.events INFO:  eta: 1:15:35  iter: 1619  total_loss: 0.2646  loss_cls: 0.03982  loss_box_reg: 0.08994  loss_mask: 0.1264  loss_rpn_cls: 0.001533  loss_rpn_loc: 0.005567  lr: 0.002  max_mem: 7127M
[07/26 16:08:19] d2.utils.events INFO:  eta: 1:16:04  iter: 1639  total_loss: 0.2622  loss_cls: 0.0385  loss_box_reg: 0.09329  loss_mask: 0.1225  loss_rpn_cls: 0.001319  loss_rpn_loc: 0.00544  lr: 0.002  max_mem: 7127M
[07/26 16:08:34] d2.utils.events INFO:  eta: 1:15:34  iter: 1659  total_loss: 0.2619  loss_cls: 0.03804  loss_box_reg: 0.09572  loss_mask: 0.1153  loss_rpn_cls: 0.001289  loss_rpn_loc: 0.006002  lr: 0.002  max_mem: 7127M
[07/26 16:08:50] d2.utils.events INFO:  eta: 1:14:36  iter: 1679  total_loss: 0.271  loss_cls: 0.04001  loss_box_reg: 0.09495  loss_mask: 0.124  loss_rpn_cls: 0.001399  loss_rpn_loc: 0.006391  lr: 0.002  max_mem: 7127M
[07/26 16:09:05] d2.utils.events INFO:  eta: 1:14:48  iter: 1699  total_loss: 0.261  loss_cls: 0.03906  loss_box_reg: 0.08879  loss_mask: 0.1221  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.006  lr: 0.002  max_mem: 7127M
[07/26 16:09:21] d2.utils.events INFO:  eta: 1:14:30  iter: 1719  total_loss: 0.2693  loss_cls: 0.04349  loss_box_reg: 0.08993  loss_mask: 0.1236  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.005648  lr: 0.002  max_mem: 7127M
[07/26 16:09:36] d2.utils.events INFO:  eta: 1:15:04  iter: 1739  total_loss: 0.2735  loss_cls: 0.04303  loss_box_reg: 0.09399  loss_mask: 0.123  loss_rpn_cls: 0.001528  loss_rpn_loc: 0.005652  lr: 0.002  max_mem: 7127M
[07/26 16:09:52] d2.utils.events INFO:  eta: 1:13:27  iter: 1759  total_loss: 0.2431  loss_cls: 0.03704  loss_box_reg: 0.08244  loss_mask: 0.1189  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.005503  lr: 0.002  max_mem: 7127M
[07/26 16:10:07] d2.utils.events INFO:  eta: 1:13:44  iter: 1779  total_loss: 0.2504  loss_cls: 0.0368  loss_box_reg: 0.09127  loss_mask: 0.1175  loss_rpn_cls: 0.001433  loss_rpn_loc: 0.005386  lr: 0.002  max_mem: 7127M
[07/26 16:10:22] d2.utils.events INFO:  eta: 1:13:04  iter: 1799  total_loss: 0.2678  loss_cls: 0.04157  loss_box_reg: 0.09302  loss_mask: 0.1242  loss_rpn_cls: 0.001375  loss_rpn_loc: 0.0056  lr: 0.002  max_mem: 7127M
[07/26 16:10:38] d2.utils.events INFO:  eta: 1:12:51  iter: 1819  total_loss: 0.2581  loss_cls: 0.04061  loss_box_reg: 0.09035  loss_mask: 0.1213  loss_rpn_cls: 0.001632  loss_rpn_loc: 0.005942  lr: 0.002  max_mem: 7127M
[07/26 16:10:53] d2.utils.events INFO:  eta: 1:12:57  iter: 1839  total_loss: 0.2452  loss_cls: 0.03391  loss_box_reg: 0.08839  loss_mask: 0.1118  loss_rpn_cls: 0.001482  loss_rpn_loc: 0.006101  lr: 0.002  max_mem: 7127M
[07/26 16:11:09] d2.utils.events INFO:  eta: 1:12:13  iter: 1859  total_loss: 0.276  loss_cls: 0.04184  loss_box_reg: 0.09485  loss_mask: 0.1285  loss_rpn_cls: 0.001997  loss_rpn_loc: 0.005851  lr: 0.002  max_mem: 7127M
[07/26 16:11:24] d2.utils.events INFO:  eta: 1:12:15  iter: 1879  total_loss: 0.2477  loss_cls: 0.03851  loss_box_reg: 0.0899  loss_mask: 0.1122  loss_rpn_cls: 0.001106  loss_rpn_loc: 0.004489  lr: 0.002  max_mem: 7127M
[07/26 16:11:40] d2.utils.events INFO:  eta: 1:12:14  iter: 1899  total_loss: 0.2529  loss_cls: 0.03595  loss_box_reg: 0.08473  loss_mask: 0.1154  loss_rpn_cls: 0.001366  loss_rpn_loc: 0.004925  lr: 0.002  max_mem: 7127M
[07/26 16:11:55] d2.utils.events INFO:  eta: 1:11:23  iter: 1919  total_loss: 0.278  loss_cls: 0.03874  loss_box_reg: 0.09333  loss_mask: 0.1342  loss_rpn_cls: 0.0016  loss_rpn_loc: 0.005721  lr: 0.002  max_mem: 7127M
[07/26 16:12:10] d2.utils.events INFO:  eta: 1:11:17  iter: 1939  total_loss: 0.2891  loss_cls: 0.04552  loss_box_reg: 0.1024  loss_mask: 0.1322  loss_rpn_cls: 0.001659  loss_rpn_loc: 0.007206  lr: 0.002  max_mem: 7127M
[07/26 16:12:26] d2.utils.events INFO:  eta: 1:11:28  iter: 1959  total_loss: 0.2576  loss_cls: 0.04086  loss_box_reg: 0.0898  loss_mask: 0.1189  loss_rpn_cls: 0.001174  loss_rpn_loc: 0.00472  lr: 0.002  max_mem: 7127M
[07/26 16:12:41] d2.utils.events INFO:  eta: 1:10:17  iter: 1979  total_loss: 0.2509  loss_cls: 0.03691  loss_box_reg: 0.08922  loss_mask: 0.1174  loss_rpn_cls: 0.00138  loss_rpn_loc: 0.00553  lr: 0.002  max_mem: 7127M
[07/26 16:12:56] d2.utils.events INFO:  eta: 1:10:22  iter: 1999  total_loss: 0.2196  loss_cls: 0.03547  loss_box_reg: 0.07509  loss_mask: 0.1053  loss_rpn_cls: 0.0008247  loss_rpn_loc: 0.00513  lr: 0.002  max_mem: 7127M
[07/26 16:13:12] d2.utils.events INFO:  eta: 1:10:27  iter: 2019  total_loss: 0.233  loss_cls: 0.03513  loss_box_reg: 0.08097  loss_mask: 0.1056  loss_rpn_cls: 0.001318  loss_rpn_loc: 0.006086  lr: 0.002  max_mem: 7127M
[07/26 16:13:27] d2.utils.events INFO:  eta: 1:10:15  iter: 2039  total_loss: 0.2445  loss_cls: 0.03719  loss_box_reg: 0.08486  loss_mask: 0.115  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.00458  lr: 0.002  max_mem: 7203M
[07/26 16:13:43] d2.utils.events INFO:  eta: 1:09:54  iter: 2059  total_loss: 0.2406  loss_cls: 0.03428  loss_box_reg: 0.08041  loss_mask: 0.1118  loss_rpn_cls: 0.001271  loss_rpn_loc: 0.005061  lr: 0.002  max_mem: 7203M
[07/26 16:13:58] d2.utils.events INFO:  eta: 1:09:13  iter: 2079  total_loss: 0.2216  loss_cls: 0.03497  loss_box_reg: 0.07588  loss_mask: 0.1101  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.004863  lr: 0.002  max_mem: 7203M
[07/26 16:14:14] d2.utils.events INFO:  eta: 1:10:52  iter: 2099  total_loss: 0.2464  loss_cls: 0.03666  loss_box_reg: 0.08705  loss_mask: 0.1138  loss_rpn_cls: 0.00134  loss_rpn_loc: 0.005705  lr: 0.002  max_mem: 7203M
[07/26 16:14:29] d2.utils.events INFO:  eta: 1:09:11  iter: 2119  total_loss: 0.2229  loss_cls: 0.03378  loss_box_reg: 0.07855  loss_mask: 0.108  loss_rpn_cls: 0.000868  loss_rpn_loc: 0.005387  lr: 0.002  max_mem: 7203M
[07/26 16:14:45] d2.utils.events INFO:  eta: 1:08:35  iter: 2139  total_loss: 0.2388  loss_cls: 0.036  loss_box_reg: 0.0799  loss_mask: 0.1105  loss_rpn_cls: 0.0007123  loss_rpn_loc: 0.0047  lr: 0.002  max_mem: 7203M
[07/26 16:15:00] d2.utils.events INFO:  eta: 1:08:37  iter: 2159  total_loss: 0.2258  loss_cls: 0.0324  loss_box_reg: 0.07916  loss_mask: 0.1068  loss_rpn_cls: 0.0008003  loss_rpn_loc: 0.004922  lr: 0.002  max_mem: 7203M
[07/26 16:15:15] d2.utils.events INFO:  eta: 1:08:16  iter: 2179  total_loss: 0.221  loss_cls: 0.03387  loss_box_reg: 0.07973  loss_mask: 0.1055  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.004718  lr: 0.002  max_mem: 7203M
[07/26 16:15:31] d2.utils.events INFO:  eta: 1:08:52  iter: 2199  total_loss: 0.2329  loss_cls: 0.03483  loss_box_reg: 0.08404  loss_mask: 0.1006  loss_rpn_cls: 0.001097  loss_rpn_loc: 0.005503  lr: 0.002  max_mem: 7203M
[07/26 16:15:46] d2.utils.events INFO:  eta: 1:07:07  iter: 2219  total_loss: 0.2199  loss_cls: 0.03225  loss_box_reg: 0.07888  loss_mask: 0.1054  loss_rpn_cls: 0.0008774  loss_rpn_loc: 0.0045  lr: 0.002  max_mem: 7203M
[07/26 16:16:01] d2.utils.events INFO:  eta: 1:06:15  iter: 2239  total_loss: 0.219  loss_cls: 0.0294  loss_box_reg: 0.06744  loss_mask: 0.1071  loss_rpn_cls: 0.0009884  loss_rpn_loc: 0.005057  lr: 0.002  max_mem: 7203M
[07/26 16:16:17] d2.utils.events INFO:  eta: 1:07:08  iter: 2259  total_loss: 0.2219  loss_cls: 0.03262  loss_box_reg: 0.07741  loss_mask: 0.1004  loss_rpn_cls: 0.001256  loss_rpn_loc: 0.004851  lr: 0.002  max_mem: 7203M
[07/26 16:16:32] d2.utils.events INFO:  eta: 1:07:21  iter: 2279  total_loss: 0.2176  loss_cls: 0.0327  loss_box_reg: 0.07509  loss_mask: 0.104  loss_rpn_cls: 0.001713  loss_rpn_loc: 0.004595  lr: 0.002  max_mem: 7203M
[07/26 16:16:48] d2.utils.events INFO:  eta: 1:06:52  iter: 2299  total_loss: 0.218  loss_cls: 0.03313  loss_box_reg: 0.08416  loss_mask: 0.0968  loss_rpn_cls: 0.0007603  loss_rpn_loc: 0.005286  lr: 0.002  max_mem: 7203M
[07/26 16:17:03] d2.utils.events INFO:  eta: 1:06:21  iter: 2319  total_loss: 0.2062  loss_cls: 0.03055  loss_box_reg: 0.07155  loss_mask: 0.09629  loss_rpn_cls: 0.0007616  loss_rpn_loc: 0.004901  lr: 0.002  max_mem: 7203M
[07/26 16:17:18] d2.utils.events INFO:  eta: 1:05:31  iter: 2339  total_loss: 0.2075  loss_cls: 0.02924  loss_box_reg: 0.07268  loss_mask: 0.09985  loss_rpn_cls: 0.0008939  loss_rpn_loc: 0.004598  lr: 0.002  max_mem: 7203M
[07/26 16:17:34] d2.utils.events INFO:  eta: 1:05:52  iter: 2359  total_loss: 0.2133  loss_cls: 0.02962  loss_box_reg: 0.07217  loss_mask: 0.1012  loss_rpn_cls: 0.0008204  loss_rpn_loc: 0.004657  lr: 0.002  max_mem: 7203M
[07/26 16:17:49] d2.utils.events INFO:  eta: 1:05:12  iter: 2379  total_loss: 0.2055  loss_cls: 0.03031  loss_box_reg: 0.07398  loss_mask: 0.09796  loss_rpn_cls: 0.000924  loss_rpn_loc: 0.004019  lr: 0.002  max_mem: 7203M
[07/26 16:18:04] d2.utils.events INFO:  eta: 1:05:44  iter: 2399  total_loss: 0.2095  loss_cls: 0.03008  loss_box_reg: 0.07519  loss_mask: 0.09532  loss_rpn_cls: 0.0006824  loss_rpn_loc: 0.004319  lr: 0.002  max_mem: 7203M
[07/26 16:18:20] d2.utils.events INFO:  eta: 1:04:48  iter: 2419  total_loss: 0.2271  loss_cls: 0.03416  loss_box_reg: 0.07859  loss_mask: 0.1106  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.005625  lr: 0.002  max_mem: 7203M
[07/26 16:18:35] d2.utils.events INFO:  eta: 1:05:40  iter: 2439  total_loss: 0.2043  loss_cls: 0.02952  loss_box_reg: 0.07067  loss_mask: 0.09472  loss_rpn_cls: 0.0007983  loss_rpn_loc: 0.00513  lr: 0.002  max_mem: 7203M
[07/26 16:18:51] d2.utils.events INFO:  eta: 1:04:43  iter: 2459  total_loss: 0.1988  loss_cls: 0.02851  loss_box_reg: 0.06974  loss_mask: 0.09407  loss_rpn_cls: 0.0009092  loss_rpn_loc: 0.005133  lr: 0.002  max_mem: 7203M
[07/26 16:19:06] d2.utils.events INFO:  eta: 1:03:59  iter: 2479  total_loss: 0.1984  loss_cls: 0.02933  loss_box_reg: 0.06807  loss_mask: 0.09351  loss_rpn_cls: 0.0007045  loss_rpn_loc: 0.004457  lr: 0.002  max_mem: 7203M
[07/26 16:19:21] d2.utils.events INFO:  eta: 1:04:02  iter: 2499  total_loss: 0.1985  loss_cls: 0.02938  loss_box_reg: 0.06851  loss_mask: 0.09159  loss_rpn_cls: 0.0009082  loss_rpn_loc: 0.004881  lr: 0.002  max_mem: 7203M
[07/26 16:19:37] d2.utils.events INFO:  eta: 1:03:50  iter: 2519  total_loss: 0.2054  loss_cls: 0.03049  loss_box_reg: 0.07148  loss_mask: 0.09399  loss_rpn_cls: 0.0006302  loss_rpn_loc: 0.004896  lr: 0.002  max_mem: 7203M
[07/26 16:19:52] d2.utils.events INFO:  eta: 1:03:25  iter: 2539  total_loss: 0.2191  loss_cls: 0.03316  loss_box_reg: 0.07595  loss_mask: 0.1082  loss_rpn_cls: 0.001167  loss_rpn_loc: 0.004948  lr: 0.002  max_mem: 7203M
[07/26 16:20:07] d2.utils.events INFO:  eta: 1:02:45  iter: 2559  total_loss: 0.2032  loss_cls: 0.02832  loss_box_reg: 0.07041  loss_mask: 0.09939  loss_rpn_cls: 0.001165  loss_rpn_loc: 0.005114  lr: 0.002  max_mem: 7203M
[07/26 16:20:23] d2.utils.events INFO:  eta: 1:02:43  iter: 2579  total_loss: 0.2058  loss_cls: 0.02823  loss_box_reg: 0.06793  loss_mask: 0.09641  loss_rpn_cls: 0.0009178  loss_rpn_loc: 0.004887  lr: 0.002  max_mem: 7203M
[07/26 16:20:38] d2.utils.events INFO:  eta: 1:03:14  iter: 2599  total_loss: 0.209  loss_cls: 0.03147  loss_box_reg: 0.0713  loss_mask: 0.09941  loss_rpn_cls: 0.0009295  loss_rpn_loc: 0.004958  lr: 0.002  max_mem: 7203M
[07/26 16:20:53] d2.utils.events INFO:  eta: 1:02:16  iter: 2619  total_loss: 0.1954  loss_cls: 0.02979  loss_box_reg: 0.06949  loss_mask: 0.09249  loss_rpn_cls: 0.000807  loss_rpn_loc: 0.00408  lr: 0.002  max_mem: 7203M
[07/26 16:21:09] d2.utils.events INFO:  eta: 1:02:24  iter: 2639  total_loss: 0.1921  loss_cls: 0.02604  loss_box_reg: 0.06631  loss_mask: 0.09419  loss_rpn_cls: 0.0006103  loss_rpn_loc: 0.003893  lr: 0.002  max_mem: 7203M
[07/26 16:21:24] d2.utils.events INFO:  eta: 1:01:53  iter: 2659  total_loss: 0.2013  loss_cls: 0.03065  loss_box_reg: 0.07117  loss_mask: 0.09416  loss_rpn_cls: 0.0007863  loss_rpn_loc: 0.005044  lr: 0.002  max_mem: 7203M
[07/26 16:21:40] d2.utils.events INFO:  eta: 1:01:42  iter: 2679  total_loss: 0.202  loss_cls: 0.03085  loss_box_reg: 0.07308  loss_mask: 0.09805  loss_rpn_cls: 0.0008091  loss_rpn_loc: 0.004955  lr: 0.002  max_mem: 7203M
[07/26 16:21:55] d2.utils.events INFO:  eta: 1:01:48  iter: 2699  total_loss: 0.198  loss_cls: 0.02698  loss_box_reg: 0.07186  loss_mask: 0.09412  loss_rpn_cls: 0.0008085  loss_rpn_loc: 0.004851  lr: 0.002  max_mem: 7203M
[07/26 16:22:10] d2.utils.events INFO:  eta: 1:00:36  iter: 2719  total_loss: 0.1969  loss_cls: 0.02828  loss_box_reg: 0.06873  loss_mask: 0.09456  loss_rpn_cls: 0.0006826  loss_rpn_loc: 0.005258  lr: 0.002  max_mem: 7203M
[07/26 16:22:26] d2.utils.events INFO:  eta: 1:00:49  iter: 2739  total_loss: 0.2011  loss_cls: 0.02818  loss_box_reg: 0.0717  loss_mask: 0.09645  loss_rpn_cls: 0.000888  loss_rpn_loc: 0.004868  lr: 0.002  max_mem: 7203M
[07/26 16:22:41] d2.utils.events INFO:  eta: 1:01:26  iter: 2759  total_loss: 0.1861  loss_cls: 0.02909  loss_box_reg: 0.06324  loss_mask: 0.08816  loss_rpn_cls: 0.0008799  loss_rpn_loc: 0.00422  lr: 0.002  max_mem: 7203M
[07/26 16:22:56] d2.utils.events INFO:  eta: 1:00:19  iter: 2779  total_loss: 0.2034  loss_cls: 0.02853  loss_box_reg: 0.07196  loss_mask: 0.09646  loss_rpn_cls: 0.0006597  loss_rpn_loc: 0.004755  lr: 0.002  max_mem: 7203M
[07/26 16:23:12] d2.utils.events INFO:  eta: 1:00:11  iter: 2799  total_loss: 0.1924  loss_cls: 0.02635  loss_box_reg: 0.06149  loss_mask: 0.09332  loss_rpn_cls: 0.0007335  loss_rpn_loc: 0.004005  lr: 0.002  max_mem: 7203M
[07/26 16:23:27] d2.utils.events INFO:  eta: 0:58:55  iter: 2819  total_loss: 0.1731  loss_cls: 0.02552  loss_box_reg: 0.05563  loss_mask: 0.08669  loss_rpn_cls: 0.0006783  loss_rpn_loc: 0.003928  lr: 0.002  max_mem: 7203M
[07/26 16:23:42] d2.utils.events INFO:  eta: 0:59:12  iter: 2839  total_loss: 0.1855  loss_cls: 0.02593  loss_box_reg: 0.06138  loss_mask: 0.09134  loss_rpn_cls: 0.0007999  loss_rpn_loc: 0.004523  lr: 0.002  max_mem: 7203M
[07/26 16:23:58] d2.utils.events INFO:  eta: 0:59:55  iter: 2859  total_loss: 0.1824  loss_cls: 0.0269  loss_box_reg: 0.0628  loss_mask: 0.09109  loss_rpn_cls: 0.0009281  loss_rpn_loc: 0.004399  lr: 0.002  max_mem: 7203M
[07/26 16:24:13] d2.utils.events INFO:  eta: 0:59:21  iter: 2879  total_loss: 0.1962  loss_cls: 0.0268  loss_box_reg: 0.06379  loss_mask: 0.08817  loss_rpn_cls: 0.0007929  loss_rpn_loc: 0.003703  lr: 0.002  max_mem: 7203M
[07/26 16:24:28] d2.utils.events INFO:  eta: 0:58:57  iter: 2899  total_loss: 0.1785  loss_cls: 0.02425  loss_box_reg: 0.06297  loss_mask: 0.09497  loss_rpn_cls: 0.0006462  loss_rpn_loc: 0.003973  lr: 0.002  max_mem: 7203M
[07/26 16:24:44] d2.utils.events INFO:  eta: 0:58:51  iter: 2919  total_loss: 0.186  loss_cls: 0.02589  loss_box_reg: 0.06098  loss_mask: 0.09437  loss_rpn_cls: 0.000709  loss_rpn_loc: 0.004243  lr: 0.002  max_mem: 7203M
[07/26 16:24:59] d2.utils.events INFO:  eta: 0:57:29  iter: 2939  total_loss: 0.177  loss_cls: 0.02536  loss_box_reg: 0.06105  loss_mask: 0.08505  loss_rpn_cls: 0.0006518  loss_rpn_loc: 0.004137  lr: 0.002  max_mem: 7203M
[07/26 16:25:14] d2.utils.events INFO:  eta: 0:57:21  iter: 2959  total_loss: 0.1717  loss_cls: 0.0234  loss_box_reg: 0.05877  loss_mask: 0.08649  loss_rpn_cls: 0.0005221  loss_rpn_loc: 0.004029  lr: 0.002  max_mem: 7203M
[07/26 16:25:29] d2.utils.events INFO:  eta: 0:57:37  iter: 2979  total_loss: 0.1895  loss_cls: 0.02734  loss_box_reg: 0.0651  loss_mask: 0.08678  loss_rpn_cls: 0.0007682  loss_rpn_loc: 0.003941  lr: 0.002  max_mem: 7203M
[07/26 16:25:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/26 16:25:45] d2.data.common INFO: Serializing 45 elements to byte tensors and concatenating them all ...
[07/26 16:25:45] d2.data.common INFO: Serialized dataset takes 0.06 MiB
[07/26 16:25:45] d2.evaluation.evaluator INFO: Start inference on 45 batches
[07/26 16:25:46] d2.evaluation.evaluator INFO: Inference done 11/45. Dataloading: 0.0005 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0606 s/iter. ETA=0:00:02
[07/26 16:25:48] d2.evaluation.evaluator INFO: Total inference time: 0:00:02.491653 (0.062291 s / iter per device, on 1 devices)
[07/26 16:25:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.059230 s / iter per device, on 1 devices)
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Saving results to output/with_augmentation/inference/for_detectron_synth_val/coco_instances_results.json
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.027 | 1.980  | 0.371  | 0.000 | 1.027 | 0.000 |
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 2.054 |
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:25:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.866 | 1.980  | 0.371  | 0.000 | 0.866 | 0.000 |
[07/26 16:25:48] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 1.733 |
[07/26 16:25:48] detectron2 INFO: Evaluation results for for_detectron_synth_val in csv format:
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: 1.0272,1.9802,0.3713,0.0000,1.0272,0.0000
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: Task: segm
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:25:48] d2.evaluation.testing INFO: copypaste: 0.8663,1.9802,0.3713,0.0000,0.8663,0.0000
[07/26 16:25:48] d2.utils.events INFO:  eta: 1:11:09  iter: 2999  total_loss: 0.1837  loss_cls: 0.02449  loss_box_reg: 0.0599  loss_mask: 0.0887  loss_rpn_cls: 0.0006529  loss_rpn_loc: 0.004153  lr: 0.002  max_mem: 7203M
[07/26 16:26:04] d2.utils.events INFO:  eta: 0:57:21  iter: 3019  total_loss: 0.1861  loss_cls: 0.0275  loss_box_reg: 0.06717  loss_mask: 0.08879  loss_rpn_cls: 0.0005618  loss_rpn_loc: 0.004331  lr: 0.002  max_mem: 7203M
[07/26 16:26:19] d2.utils.events INFO:  eta: 0:56:20  iter: 3039  total_loss: 0.1795  loss_cls: 0.02481  loss_box_reg: 0.06071  loss_mask: 0.08845  loss_rpn_cls: 0.0004993  loss_rpn_loc: 0.004159  lr: 0.002  max_mem: 7203M
[07/26 16:26:34] d2.utils.events INFO:  eta: 0:56:19  iter: 3059  total_loss: 0.1857  loss_cls: 0.02586  loss_box_reg: 0.06501  loss_mask: 0.08962  loss_rpn_cls: 0.0008748  loss_rpn_loc: 0.004101  lr: 0.002  max_mem: 7203M
[07/26 16:26:49] d2.utils.events INFO:  eta: 0:55:59  iter: 3079  total_loss: 0.1771  loss_cls: 0.02336  loss_box_reg: 0.06015  loss_mask: 0.08769  loss_rpn_cls: 0.0005269  loss_rpn_loc: 0.004234  lr: 0.002  max_mem: 7203M
[07/26 16:27:05] d2.utils.events INFO:  eta: 0:55:47  iter: 3099  total_loss: 0.1839  loss_cls: 0.0263  loss_box_reg: 0.06635  loss_mask: 0.08533  loss_rpn_cls: 0.0005323  loss_rpn_loc: 0.004155  lr: 0.002  max_mem: 7203M
[07/26 16:27:20] d2.utils.events INFO:  eta: 0:55:19  iter: 3119  total_loss: 0.182  loss_cls: 0.02295  loss_box_reg: 0.05893  loss_mask: 0.08706  loss_rpn_cls: 0.0005892  loss_rpn_loc: 0.004077  lr: 0.002  max_mem: 7203M
[07/26 16:27:35] d2.utils.events INFO:  eta: 0:55:27  iter: 3139  total_loss: 0.1692  loss_cls: 0.0231  loss_box_reg: 0.05915  loss_mask: 0.08331  loss_rpn_cls: 0.0005276  loss_rpn_loc: 0.003942  lr: 0.002  max_mem: 7203M
[07/26 16:27:50] d2.utils.events INFO:  eta: 0:54:46  iter: 3159  total_loss: 0.1723  loss_cls: 0.02609  loss_box_reg: 0.05915  loss_mask: 0.0844  loss_rpn_cls: 0.0006059  loss_rpn_loc: 0.003987  lr: 0.002  max_mem: 7203M
[07/26 16:28:06] d2.utils.events INFO:  eta: 0:55:32  iter: 3179  total_loss: 0.1794  loss_cls: 0.02549  loss_box_reg: 0.06209  loss_mask: 0.08951  loss_rpn_cls: 0.0005984  loss_rpn_loc: 0.003993  lr: 0.002  max_mem: 7203M
[07/26 16:28:21] d2.utils.events INFO:  eta: 0:54:35  iter: 3199  total_loss: 0.2109  loss_cls: 0.02768  loss_box_reg: 0.0714  loss_mask: 0.1015  loss_rpn_cls: 0.0009265  loss_rpn_loc: 0.004353  lr: 0.002  max_mem: 7203M
[07/26 16:28:36] d2.utils.events INFO:  eta: 0:54:40  iter: 3219  total_loss: 0.2008  loss_cls: 0.02728  loss_box_reg: 0.06546  loss_mask: 0.09871  loss_rpn_cls: 0.0008251  loss_rpn_loc: 0.004984  lr: 0.002  max_mem: 7203M
[07/26 16:28:51] d2.utils.events INFO:  eta: 0:53:27  iter: 3239  total_loss: 0.2185  loss_cls: 0.03071  loss_box_reg: 0.0756  loss_mask: 0.1117  loss_rpn_cls: 0.00098  loss_rpn_loc: 0.004775  lr: 0.002  max_mem: 7203M
[07/26 16:29:06] d2.utils.events INFO:  eta: 0:53:12  iter: 3259  total_loss: 0.1882  loss_cls: 0.02545  loss_box_reg: 0.06062  loss_mask: 0.09061  loss_rpn_cls: 0.0005006  loss_rpn_loc: 0.003733  lr: 0.002  max_mem: 7203M
[07/26 16:29:22] d2.utils.events INFO:  eta: 0:53:45  iter: 3279  total_loss: 0.1876  loss_cls: 0.02746  loss_box_reg: 0.06421  loss_mask: 0.08601  loss_rpn_cls: 0.0007904  loss_rpn_loc: 0.004174  lr: 0.002  max_mem: 7203M
[07/26 16:29:37] d2.utils.events INFO:  eta: 0:52:40  iter: 3299  total_loss: 0.177  loss_cls: 0.02453  loss_box_reg: 0.06052  loss_mask: 0.08747  loss_rpn_cls: 0.000619  loss_rpn_loc: 0.004671  lr: 0.002  max_mem: 7203M
[07/26 16:29:52] d2.utils.events INFO:  eta: 0:52:16  iter: 3319  total_loss: 0.1712  loss_cls: 0.02322  loss_box_reg: 0.05417  loss_mask: 0.08848  loss_rpn_cls: 0.0006088  loss_rpn_loc: 0.003766  lr: 0.002  max_mem: 7203M
[07/26 16:30:07] d2.utils.events INFO:  eta: 0:52:15  iter: 3339  total_loss: 0.1728  loss_cls: 0.02287  loss_box_reg: 0.05707  loss_mask: 0.08997  loss_rpn_cls: 0.0008839  loss_rpn_loc: 0.00434  lr: 0.002  max_mem: 7203M
[07/26 16:30:22] d2.utils.events INFO:  eta: 0:52:13  iter: 3359  total_loss: 0.1793  loss_cls: 0.02544  loss_box_reg: 0.0613  loss_mask: 0.08545  loss_rpn_cls: 0.0005859  loss_rpn_loc: 0.00393  lr: 0.002  max_mem: 7203M
[07/26 16:30:37] d2.utils.events INFO:  eta: 0:52:00  iter: 3379  total_loss: 0.1656  loss_cls: 0.02294  loss_box_reg: 0.05515  loss_mask: 0.08189  loss_rpn_cls: 0.0005488  loss_rpn_loc: 0.003913  lr: 0.002  max_mem: 7203M
[07/26 16:30:52] d2.utils.events INFO:  eta: 0:51:11  iter: 3399  total_loss: 0.1571  loss_cls: 0.02135  loss_box_reg: 0.05086  loss_mask: 0.08006  loss_rpn_cls: 0.0004823  loss_rpn_loc: 0.003887  lr: 0.002  max_mem: 7203M
[07/26 16:31:07] d2.utils.events INFO:  eta: 0:51:37  iter: 3419  total_loss: 0.1742  loss_cls: 0.02479  loss_box_reg: 0.06275  loss_mask: 0.08259  loss_rpn_cls: 0.0005555  loss_rpn_loc: 0.003954  lr: 0.002  max_mem: 7203M
[07/26 16:31:22] d2.utils.events INFO:  eta: 0:50:59  iter: 3439  total_loss: 0.1723  loss_cls: 0.02484  loss_box_reg: 0.05997  loss_mask: 0.08599  loss_rpn_cls: 0.0005597  loss_rpn_loc: 0.004093  lr: 0.002  max_mem: 7203M
[07/26 16:31:37] d2.utils.events INFO:  eta: 0:50:31  iter: 3459  total_loss: 0.1754  loss_cls: 0.02275  loss_box_reg: 0.05658  loss_mask: 0.08642  loss_rpn_cls: 0.0006473  loss_rpn_loc: 0.00378  lr: 0.002  max_mem: 7203M
[07/26 16:31:53] d2.utils.events INFO:  eta: 0:51:12  iter: 3479  total_loss: 0.1668  loss_cls: 0.02464  loss_box_reg: 0.05897  loss_mask: 0.08202  loss_rpn_cls: 0.0005108  loss_rpn_loc: 0.003679  lr: 0.002  max_mem: 7203M
[07/26 16:32:08] d2.utils.events INFO:  eta: 0:50:09  iter: 3499  total_loss: 0.1697  loss_cls: 0.02359  loss_box_reg: 0.0542  loss_mask: 0.08367  loss_rpn_cls: 0.0005677  loss_rpn_loc: 0.003831  lr: 0.002  max_mem: 7203M
[07/26 16:32:23] d2.utils.events INFO:  eta: 0:50:29  iter: 3519  total_loss: 0.1593  loss_cls: 0.02406  loss_box_reg: 0.05471  loss_mask: 0.0795  loss_rpn_cls: 0.0004986  loss_rpn_loc: 0.004277  lr: 0.002  max_mem: 7203M
[07/26 16:32:38] d2.utils.events INFO:  eta: 0:49:51  iter: 3539  total_loss: 0.1712  loss_cls: 0.02509  loss_box_reg: 0.06098  loss_mask: 0.07987  loss_rpn_cls: 0.0004376  loss_rpn_loc: 0.003914  lr: 0.002  max_mem: 7203M
[07/26 16:32:53] d2.utils.events INFO:  eta: 0:49:39  iter: 3559  total_loss: 0.1713  loss_cls: 0.02489  loss_box_reg: 0.05829  loss_mask: 0.08421  loss_rpn_cls: 0.0005596  loss_rpn_loc: 0.003723  lr: 0.002  max_mem: 7203M
[07/26 16:33:08] d2.utils.events INFO:  eta: 0:49:14  iter: 3579  total_loss: 0.172  loss_cls: 0.02335  loss_box_reg: 0.05544  loss_mask: 0.08305  loss_rpn_cls: 0.0007308  loss_rpn_loc: 0.004221  lr: 0.002  max_mem: 7203M
[07/26 16:33:23] d2.utils.events INFO:  eta: 0:49:52  iter: 3599  total_loss: 0.1664  loss_cls: 0.02386  loss_box_reg: 0.05454  loss_mask: 0.08175  loss_rpn_cls: 0.0006015  loss_rpn_loc: 0.003968  lr: 0.002  max_mem: 7203M
[07/26 16:33:39] d2.utils.events INFO:  eta: 0:48:49  iter: 3619  total_loss: 0.1638  loss_cls: 0.02284  loss_box_reg: 0.05538  loss_mask: 0.0808  loss_rpn_cls: 0.0004946  loss_rpn_loc: 0.003931  lr: 0.002  max_mem: 7203M
[07/26 16:33:54] d2.utils.events INFO:  eta: 0:48:20  iter: 3639  total_loss: 0.1604  loss_cls: 0.0224  loss_box_reg: 0.05268  loss_mask: 0.08055  loss_rpn_cls: 0.0004546  loss_rpn_loc: 0.003428  lr: 0.002  max_mem: 7203M
[07/26 16:34:09] d2.utils.events INFO:  eta: 0:48:54  iter: 3659  total_loss: 0.1713  loss_cls: 0.02498  loss_box_reg: 0.05969  loss_mask: 0.08296  loss_rpn_cls: 0.0006028  loss_rpn_loc: 0.004204  lr: 0.002  max_mem: 7203M
[07/26 16:34:24] d2.utils.events INFO:  eta: 0:48:20  iter: 3679  total_loss: 0.1695  loss_cls: 0.02628  loss_box_reg: 0.05842  loss_mask: 0.08146  loss_rpn_cls: 0.000432  loss_rpn_loc: 0.003975  lr: 0.002  max_mem: 7203M
[07/26 16:34:39] d2.utils.events INFO:  eta: 0:48:00  iter: 3699  total_loss: 0.1531  loss_cls: 0.02217  loss_box_reg: 0.05088  loss_mask: 0.07737  loss_rpn_cls: 0.0005232  loss_rpn_loc: 0.003655  lr: 0.002  max_mem: 7203M
[07/26 16:34:54] d2.utils.events INFO:  eta: 0:47:07  iter: 3719  total_loss: 0.1629  loss_cls: 0.02084  loss_box_reg: 0.05327  loss_mask: 0.08231  loss_rpn_cls: 0.0004955  loss_rpn_loc: 0.003678  lr: 0.002  max_mem: 7203M
[07/26 16:35:09] d2.utils.events INFO:  eta: 0:47:34  iter: 3739  total_loss: 0.1574  loss_cls: 0.02286  loss_box_reg: 0.05247  loss_mask: 0.08361  loss_rpn_cls: 0.0004398  loss_rpn_loc: 0.00356  lr: 0.002  max_mem: 7203M
[07/26 16:35:25] d2.utils.events INFO:  eta: 0:47:19  iter: 3759  total_loss: 0.1491  loss_cls: 0.02179  loss_box_reg: 0.05019  loss_mask: 0.07903  loss_rpn_cls: 0.000344  loss_rpn_loc: 0.003103  lr: 0.002  max_mem: 7203M
[07/26 16:35:40] d2.utils.events INFO:  eta: 0:47:17  iter: 3779  total_loss: 0.1586  loss_cls: 0.02036  loss_box_reg: 0.05182  loss_mask: 0.08419  loss_rpn_cls: 0.0006509  loss_rpn_loc: 0.003719  lr: 0.002  max_mem: 7203M
[07/26 16:35:55] d2.utils.events INFO:  eta: 0:46:49  iter: 3799  total_loss: 0.151  loss_cls: 0.02101  loss_box_reg: 0.0527  loss_mask: 0.07718  loss_rpn_cls: 0.0006354  loss_rpn_loc: 0.004337  lr: 0.002  max_mem: 7203M
[07/26 16:36:10] d2.utils.events INFO:  eta: 0:46:52  iter: 3819  total_loss: 0.1523  loss_cls: 0.01998  loss_box_reg: 0.05189  loss_mask: 0.07868  loss_rpn_cls: 0.000324  loss_rpn_loc: 0.003519  lr: 0.002  max_mem: 7203M
[07/26 16:36:26] d2.utils.events INFO:  eta: 0:46:37  iter: 3839  total_loss: 0.167  loss_cls: 0.0233  loss_box_reg: 0.05793  loss_mask: 0.08151  loss_rpn_cls: 0.0005875  loss_rpn_loc: 0.003993  lr: 0.002  max_mem: 7203M
[07/26 16:36:41] d2.utils.events INFO:  eta: 0:45:38  iter: 3859  total_loss: 0.1506  loss_cls: 0.02137  loss_box_reg: 0.05227  loss_mask: 0.07368  loss_rpn_cls: 0.0004982  loss_rpn_loc: 0.003505  lr: 0.002  max_mem: 7203M
[07/26 16:36:56] d2.utils.events INFO:  eta: 0:45:24  iter: 3879  total_loss: 0.1612  loss_cls: 0.02188  loss_box_reg: 0.05622  loss_mask: 0.07766  loss_rpn_cls: 0.0003944  loss_rpn_loc: 0.003084  lr: 0.002  max_mem: 7203M
[07/26 16:37:11] d2.utils.events INFO:  eta: 0:46:03  iter: 3899  total_loss: 0.1701  loss_cls: 0.02538  loss_box_reg: 0.06087  loss_mask: 0.08194  loss_rpn_cls: 0.000749  loss_rpn_loc: 0.003895  lr: 0.002  max_mem: 7203M
[07/26 16:37:26] d2.utils.events INFO:  eta: 0:45:00  iter: 3919  total_loss: 0.1631  loss_cls: 0.0206  loss_box_reg: 0.05663  loss_mask: 0.08216  loss_rpn_cls: 0.0004023  loss_rpn_loc: 0.004095  lr: 0.002  max_mem: 7203M
[07/26 16:37:41] d2.utils.events INFO:  eta: 0:45:02  iter: 3939  total_loss: 0.2085  loss_cls: 0.02764  loss_box_reg: 0.07181  loss_mask: 0.1002  loss_rpn_cls: 0.0006675  loss_rpn_loc: 0.004401  lr: 0.002  max_mem: 7203M
[07/26 16:37:56] d2.utils.events INFO:  eta: 0:44:26  iter: 3959  total_loss: 0.1725  loss_cls: 0.02389  loss_box_reg: 0.0593  loss_mask: 0.08538  loss_rpn_cls: 0.0006305  loss_rpn_loc: 0.004045  lr: 0.002  max_mem: 7203M
[07/26 16:38:11] d2.utils.events INFO:  eta: 0:44:25  iter: 3979  total_loss: 0.1685  loss_cls: 0.02342  loss_box_reg: 0.05504  loss_mask: 0.08341  loss_rpn_cls: 0.0005578  loss_rpn_loc: 0.003477  lr: 0.002  max_mem: 7203M
[07/26 16:38:26] d2.utils.events INFO:  eta: 0:43:46  iter: 3999  total_loss: 0.1615  loss_cls: 0.02113  loss_box_reg: 0.05439  loss_mask: 0.08238  loss_rpn_cls: 0.0004835  loss_rpn_loc: 0.003887  lr: 0.002  max_mem: 7203M
[07/26 16:38:42] d2.utils.events INFO:  eta: 0:43:35  iter: 4019  total_loss: 0.1651  loss_cls: 0.023  loss_box_reg: 0.05559  loss_mask: 0.08143  loss_rpn_cls: 0.0004636  loss_rpn_loc: 0.004053  lr: 0.002  max_mem: 7203M
[07/26 16:38:57] d2.utils.events INFO:  eta: 0:43:42  iter: 4039  total_loss: 0.163  loss_cls: 0.024  loss_box_reg: 0.05004  loss_mask: 0.07945  loss_rpn_cls: 0.0004123  loss_rpn_loc: 0.003335  lr: 0.002  max_mem: 7203M
[07/26 16:39:12] d2.utils.events INFO:  eta: 0:43:06  iter: 4059  total_loss: 0.155  loss_cls: 0.02169  loss_box_reg: 0.05247  loss_mask: 0.07597  loss_rpn_cls: 0.0004663  loss_rpn_loc: 0.003754  lr: 0.002  max_mem: 7203M
[07/26 16:39:27] d2.utils.events INFO:  eta: 0:43:07  iter: 4079  total_loss: 0.1569  loss_cls: 0.01977  loss_box_reg: 0.05019  loss_mask: 0.08038  loss_rpn_cls: 0.0003585  loss_rpn_loc: 0.003482  lr: 0.002  max_mem: 7203M
[07/26 16:39:42] d2.utils.events INFO:  eta: 0:42:40  iter: 4099  total_loss: 0.1581  loss_cls: 0.02023  loss_box_reg: 0.05484  loss_mask: 0.08012  loss_rpn_cls: 0.0003453  loss_rpn_loc: 0.003307  lr: 0.002  max_mem: 7203M
[07/26 16:39:57] d2.utils.events INFO:  eta: 0:42:54  iter: 4119  total_loss: 0.1594  loss_cls: 0.02349  loss_box_reg: 0.05355  loss_mask: 0.0812  loss_rpn_cls: 0.0005865  loss_rpn_loc: 0.003422  lr: 0.002  max_mem: 7203M
[07/26 16:40:12] d2.utils.events INFO:  eta: 0:42:13  iter: 4139  total_loss: 0.1557  loss_cls: 0.02229  loss_box_reg: 0.05269  loss_mask: 0.07452  loss_rpn_cls: 0.0003718  loss_rpn_loc: 0.003548  lr: 0.002  max_mem: 7203M
[07/26 16:40:27] d2.utils.events INFO:  eta: 0:41:53  iter: 4159  total_loss: 0.1623  loss_cls: 0.02186  loss_box_reg: 0.05348  loss_mask: 0.07855  loss_rpn_cls: 0.0004526  loss_rpn_loc: 0.004182  lr: 0.002  max_mem: 7203M
[07/26 16:40:42] d2.utils.events INFO:  eta: 0:42:00  iter: 4179  total_loss: 0.1554  loss_cls: 0.02207  loss_box_reg: 0.05227  loss_mask: 0.0761  loss_rpn_cls: 0.0005545  loss_rpn_loc: 0.003716  lr: 0.002  max_mem: 7203M
[07/26 16:40:58] d2.utils.events INFO:  eta: 0:41:27  iter: 4199  total_loss: 0.1508  loss_cls: 0.02188  loss_box_reg: 0.05103  loss_mask: 0.07415  loss_rpn_cls: 0.0005019  loss_rpn_loc: 0.003229  lr: 0.002  max_mem: 7203M
[07/26 16:41:13] d2.utils.events INFO:  eta: 0:40:59  iter: 4219  total_loss: 0.1545  loss_cls: 0.02212  loss_box_reg: 0.05035  loss_mask: 0.07738  loss_rpn_cls: 0.0003976  loss_rpn_loc: 0.003615  lr: 0.002  max_mem: 7203M
[07/26 16:41:28] d2.utils.events INFO:  eta: 0:41:05  iter: 4239  total_loss: 0.1531  loss_cls: 0.0204  loss_box_reg: 0.04901  loss_mask: 0.07505  loss_rpn_cls: 0.0004282  loss_rpn_loc: 0.003406  lr: 0.002  max_mem: 7203M
[07/26 16:41:43] d2.utils.events INFO:  eta: 0:40:41  iter: 4259  total_loss: 0.1464  loss_cls: 0.01983  loss_box_reg: 0.04712  loss_mask: 0.07612  loss_rpn_cls: 0.0005078  loss_rpn_loc: 0.003534  lr: 0.002  max_mem: 7203M
[07/26 16:41:58] d2.utils.events INFO:  eta: 0:40:57  iter: 4279  total_loss: 0.1556  loss_cls: 0.02079  loss_box_reg: 0.05029  loss_mask: 0.08129  loss_rpn_cls: 0.0004837  loss_rpn_loc: 0.003812  lr: 0.002  max_mem: 7203M
[07/26 16:42:13] d2.utils.events INFO:  eta: 0:40:16  iter: 4299  total_loss: 0.1489  loss_cls: 0.01938  loss_box_reg: 0.05112  loss_mask: 0.07355  loss_rpn_cls: 0.0003805  loss_rpn_loc: 0.003404  lr: 0.002  max_mem: 7203M
[07/26 16:42:28] d2.utils.events INFO:  eta: 0:40:03  iter: 4319  total_loss: 0.1562  loss_cls: 0.0215  loss_box_reg: 0.0531  loss_mask: 0.07746  loss_rpn_cls: 0.0004074  loss_rpn_loc: 0.003642  lr: 0.002  max_mem: 7203M
[07/26 16:42:43] d2.utils.events INFO:  eta: 0:40:01  iter: 4339  total_loss: 0.1534  loss_cls: 0.0211  loss_box_reg: 0.04483  loss_mask: 0.07638  loss_rpn_cls: 0.0003832  loss_rpn_loc: 0.003638  lr: 0.002  max_mem: 7203M
[07/26 16:42:59] d2.utils.events INFO:  eta: 0:39:50  iter: 4359  total_loss: 0.1541  loss_cls: 0.0214  loss_box_reg: 0.05418  loss_mask: 0.07504  loss_rpn_cls: 0.000593  loss_rpn_loc: 0.00398  lr: 0.002  max_mem: 7203M
[07/26 16:43:14] d2.utils.events INFO:  eta: 0:39:14  iter: 4379  total_loss: 0.1468  loss_cls: 0.01903  loss_box_reg: 0.04873  loss_mask: 0.07226  loss_rpn_cls: 0.0003825  loss_rpn_loc: 0.003465  lr: 0.002  max_mem: 7203M
[07/26 16:43:29] d2.utils.events INFO:  eta: 0:39:22  iter: 4399  total_loss: 0.151  loss_cls: 0.02063  loss_box_reg: 0.04974  loss_mask: 0.07652  loss_rpn_cls: 0.0005972  loss_rpn_loc: 0.003457  lr: 0.002  max_mem: 7203M
[07/26 16:43:44] d2.utils.events INFO:  eta: 0:38:55  iter: 4419  total_loss: 0.141  loss_cls: 0.01922  loss_box_reg: 0.0472  loss_mask: 0.06734  loss_rpn_cls: 0.0003319  loss_rpn_loc: 0.002981  lr: 0.002  max_mem: 7203M
[07/26 16:43:59] d2.utils.events INFO:  eta: 0:38:17  iter: 4439  total_loss: 0.1415  loss_cls: 0.01817  loss_box_reg: 0.04431  loss_mask: 0.0794  loss_rpn_cls: 0.0004727  loss_rpn_loc: 0.003497  lr: 0.002  max_mem: 7203M
[07/26 16:44:14] d2.utils.events INFO:  eta: 0:37:59  iter: 4459  total_loss: 0.1451  loss_cls: 0.02103  loss_box_reg: 0.0486  loss_mask: 0.07236  loss_rpn_cls: 0.0003789  loss_rpn_loc: 0.003734  lr: 0.002  max_mem: 7203M
[07/26 16:44:29] d2.utils.events INFO:  eta: 0:38:08  iter: 4479  total_loss: 0.1407  loss_cls: 0.01894  loss_box_reg: 0.04861  loss_mask: 0.07012  loss_rpn_cls: 0.0004978  loss_rpn_loc: 0.003121  lr: 0.002  max_mem: 7203M
[07/26 16:44:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/26 16:44:44] d2.data.common INFO: Serializing 45 elements to byte tensors and concatenating them all ...
[07/26 16:44:44] d2.data.common INFO: Serialized dataset takes 0.06 MiB
[07/26 16:44:44] d2.evaluation.evaluator INFO: Start inference on 45 batches
[07/26 16:44:45] d2.evaluation.evaluator INFO: Inference done 11/45. Dataloading: 0.0008 s/iter. Inference: 0.0570 s/iter. Eval: 0.0004 s/iter. Total: 0.0582 s/iter. ETA=0:00:01
[07/26 16:44:48] d2.evaluation.evaluator INFO: Total inference time: 0:00:02.407905 (0.060198 s / iter per device, on 1 devices)
[07/26 16:44:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.057214 s / iter per device, on 1 devices)
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Saving results to output/with_augmentation/inference/for_detectron_synth_val/coco_instances_results.json
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.957 | 3.465  | 0.000  | 0.000 | 0.957 | 0.000 |
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 1.914 |
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 16:44:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.660 | 3.465  | 0.000  | 0.000 | 0.660 | 0.000 |
[07/26 16:44:48] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 1.320 |
[07/26 16:44:48] detectron2 INFO: Evaluation results for for_detectron_synth_val in csv format:
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: 0.9571,3.4653,0.0000,0.0000,0.9571,0.0000
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: Task: segm
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 16:44:48] d2.evaluation.testing INFO: copypaste: 0.6601,3.4653,0.0000,0.0000,0.6601,0.0000
[07/26 16:44:48] d2.utils.events INFO:  eta: 0:45:46  iter: 4499  total_loss: 0.149  loss_cls: 0.01962  loss_box_reg: 0.04959  loss_mask: 0.07598  loss_rpn_cls: 0.000478  loss_rpn_loc: 0.003706  lr: 0.002  max_mem: 7203M
[07/26 16:45:03] d2.utils.events INFO:  eta: 0:37:00  iter: 4519  total_loss: 0.1447  loss_cls: 0.02049  loss_box_reg: 0.04863  loss_mask: 0.07272  loss_rpn_cls: 0.0003837  loss_rpn_loc: 0.003491  lr: 0.002  max_mem: 7203M
[07/26 16:45:18] d2.utils.events INFO:  eta: 0:37:25  iter: 4539  total_loss: 0.1493  loss_cls: 0.01856  loss_box_reg: 0.04686  loss_mask: 0.07858  loss_rpn_cls: 0.0004005  loss_rpn_loc: 0.003706  lr: 0.002  max_mem: 7203M
[07/26 16:45:33] d2.utils.events INFO:  eta: 0:36:57  iter: 4559  total_loss: 0.1403  loss_cls: 0.01943  loss_box_reg: 0.04834  loss_mask: 0.07318  loss_rpn_cls: 0.0003833  loss_rpn_loc: 0.003212  lr: 0.002  max_mem: 7203M
[07/26 16:45:48] d2.utils.events INFO:  eta: 0:36:27  iter: 4579  total_loss: 0.1437  loss_cls: 0.01855  loss_box_reg: 0.04813  loss_mask: 0.07429  loss_rpn_cls: 0.0002461  loss_rpn_loc: 0.002997  lr: 0.002  max_mem: 7203M
[07/26 16:46:03] d2.utils.events INFO:  eta: 0:36:31  iter: 4599  total_loss: 0.1409  loss_cls: 0.0196  loss_box_reg: 0.04555  loss_mask: 0.06901  loss_rpn_cls: 0.0003853  loss_rpn_loc: 0.003388  lr: 0.002  max_mem: 7203M
[07/26 16:46:18] d2.utils.events INFO:  eta: 0:35:53  iter: 4619  total_loss: 0.1366  loss_cls: 0.01966  loss_box_reg: 0.04074  loss_mask: 0.0706  loss_rpn_cls: 0.0004196  loss_rpn_loc: 0.003142  lr: 0.002  max_mem: 7203M
[07/26 16:46:33] d2.utils.events INFO:  eta: 0:35:31  iter: 4639  total_loss: 0.136  loss_cls: 0.01805  loss_box_reg: 0.04612  loss_mask: 0.07086  loss_rpn_cls: 0.0003205  loss_rpn_loc: 0.00322  lr: 0.002  max_mem: 7203M
[07/26 16:46:48] d2.utils.events INFO:  eta: 0:35:37  iter: 4659  total_loss: 0.1405  loss_cls: 0.01949  loss_box_reg: 0.04952  loss_mask: 0.07355  loss_rpn_cls: 0.0003742  loss_rpn_loc: 0.003425  lr: 0.002  max_mem: 7203M
[07/26 16:47:03] d2.utils.events INFO:  eta: 0:35:06  iter: 4679  total_loss: 0.1454  loss_cls: 0.01951  loss_box_reg: 0.0457  loss_mask: 0.07082  loss_rpn_cls: 0.0003227  loss_rpn_loc: 0.003891  lr: 0.002  max_mem: 7203M
[07/26 16:47:18] d2.utils.events INFO:  eta: 0:34:33  iter: 4699  total_loss: 0.1375  loss_cls: 0.01716  loss_box_reg: 0.04369  loss_mask: 0.07193  loss_rpn_cls: 0.0004169  loss_rpn_loc: 0.003657  lr: 0.002  max_mem: 7203M
[07/26 16:47:33] d2.utils.events INFO:  eta: 0:34:55  iter: 4719  total_loss: 0.1351  loss_cls: 0.01854  loss_box_reg: 0.04646  loss_mask: 0.06877  loss_rpn_cls: 0.0002054  loss_rpn_loc: 0.003142  lr: 0.002  max_mem: 7203M
[07/26 16:47:48] d2.utils.events INFO:  eta: 0:34:20  iter: 4739  total_loss: 0.147  loss_cls: 0.02027  loss_box_reg: 0.04739  loss_mask: 0.07471  loss_rpn_cls: 0.0002836  loss_rpn_loc: 0.003027  lr: 0.002  max_mem: 7203M
[07/26 16:48:03] d2.utils.events INFO:  eta: 0:34:15  iter: 4759  total_loss: 0.1347  loss_cls: 0.01754  loss_box_reg: 0.0429  loss_mask: 0.07107  loss_rpn_cls: 0.0003173  loss_rpn_loc: 0.003171  lr: 0.002  max_mem: 7203M
[07/26 16:48:17] d2.utils.events INFO:  eta: 0:33:54  iter: 4779  total_loss: 0.1468  loss_cls: 0.01917  loss_box_reg: 0.04801  loss_mask: 0.07257  loss_rpn_cls: 0.0004581  loss_rpn_loc: 0.003602  lr: 0.002  max_mem: 7203M
[07/26 16:48:32] d2.utils.events INFO:  eta: 0:33:46  iter: 4799  total_loss: 0.1383  loss_cls: 0.01782  loss_box_reg: 0.04596  loss_mask: 0.06823  loss_rpn_cls: 0.0003003  loss_rpn_loc: 0.00345  lr: 0.002  max_mem: 7203M
[07/26 16:48:48] d2.utils.events INFO:  eta: 0:33:47  iter: 4819  total_loss: 0.137  loss_cls: 0.01844  loss_box_reg: 0.04564  loss_mask: 0.06879  loss_rpn_cls: 0.0003041  loss_rpn_loc: 0.003355  lr: 0.002  max_mem: 7203M
[07/26 16:49:03] d2.utils.events INFO:  eta: 0:33:08  iter: 4839  total_loss: 0.1453  loss_cls: 0.01833  loss_box_reg: 0.04809  loss_mask: 0.07529  loss_rpn_cls: 0.0004172  loss_rpn_loc: 0.003458  lr: 0.002  max_mem: 7203M
[07/26 16:49:18] d2.utils.events INFO:  eta: 0:33:07  iter: 4859  total_loss: 0.139  loss_cls: 0.01771  loss_box_reg: 0.04577  loss_mask: 0.07018  loss_rpn_cls: 0.0003937  loss_rpn_loc: 0.003456  lr: 0.002  max_mem: 7203M
[07/26 16:49:32] d2.utils.events INFO:  eta: 0:32:26  iter: 4879  total_loss: 0.1325  loss_cls: 0.01675  loss_box_reg: 0.04132  loss_mask: 0.07073  loss_rpn_cls: 0.000315  loss_rpn_loc: 0.002917  lr: 0.002  max_mem: 7203M
[07/26 16:49:47] d2.utils.events INFO:  eta: 0:32:12  iter: 4899  total_loss: 0.139  loss_cls: 0.01775  loss_box_reg: 0.0437  loss_mask: 0.07267  loss_rpn_cls: 0.0003828  loss_rpn_loc: 0.00299  lr: 0.002  max_mem: 7203M
[07/26 16:50:02] d2.utils.events INFO:  eta: 0:32:22  iter: 4919  total_loss: 0.1342  loss_cls: 0.01615  loss_box_reg: 0.04223  loss_mask: 0.06935  loss_rpn_cls: 0.0003265  loss_rpn_loc: 0.003099  lr: 0.002  max_mem: 7203M
[07/26 16:50:17] d2.utils.events INFO:  eta: 0:32:00  iter: 4939  total_loss: 0.1337  loss_cls: 0.0185  loss_box_reg: 0.04155  loss_mask: 0.06777  loss_rpn_cls: 0.0002663  loss_rpn_loc: 0.003344  lr: 0.002  max_mem: 7203M
[07/26 16:50:32] d2.utils.events INFO:  eta: 0:31:39  iter: 4959  total_loss: 0.1314  loss_cls: 0.01856  loss_box_reg: 0.04349  loss_mask: 0.06655  loss_rpn_cls: 0.000392  loss_rpn_loc: 0.003416  lr: 0.002  max_mem: 7203M
[07/26 16:50:47] d2.utils.events INFO:  eta: 0:31:33  iter: 4979  total_loss: 0.1416  loss_cls: 0.0194  loss_box_reg: 0.04542  loss_mask: 0.07251  loss_rpn_cls: 0.0004987  loss_rpn_loc: 0.003674  lr: 0.002  max_mem: 7203M
[07/26 16:51:02] d2.utils.events INFO:  eta: 0:31:20  iter: 4999  total_loss: 0.1377  loss_cls: 0.018  loss_box_reg: 0.0455  loss_mask: 0.07129  loss_rpn_cls: 0.0002882  loss_rpn_loc: 0.003147  lr: 0.002  max_mem: 7203M
[07/26 16:51:02] fvcore.common.checkpoint INFO: Saving checkpoint to output/with_augmentation/model_0004999.pth
[07/26 16:51:38] d2.utils.events INFO:  eta: 1:12:50  iter: 5019  total_loss: 0.1465  loss_cls: 0.02042  loss_box_reg: 0.04813  loss_mask: 0.07135  loss_rpn_cls: 0.0002155  loss_rpn_loc: 0.003645  lr: 0.002  max_mem: 7203M
[07/26 16:51:53] d2.utils.events INFO:  eta: 0:30:33  iter: 5039  total_loss: 0.1392  loss_cls: 0.01958  loss_box_reg: 0.04699  loss_mask: 0.07003  loss_rpn_cls: 0.0004626  loss_rpn_loc: 0.003728  lr: 0.002  max_mem: 7203M
[07/26 16:52:07] d2.utils.events INFO:  eta: 0:30:07  iter: 5059  total_loss: 0.1584  loss_cls: 0.02063  loss_box_reg: 0.05081  loss_mask: 0.08347  loss_rpn_cls: 0.0006521  loss_rpn_loc: 0.003322  lr: 0.002  max_mem: 7203M
[07/26 16:52:23] d2.utils.events INFO:  eta: 0:30:28  iter: 5079  total_loss: 0.1508  loss_cls: 0.01963  loss_box_reg: 0.05193  loss_mask: 0.07162  loss_rpn_cls: 0.0006173  loss_rpn_loc: 0.003958  lr: 0.002  max_mem: 7203M
[07/26 16:52:38] d2.utils.events INFO:  eta: 0:29:57  iter: 5099  total_loss: 0.1437  loss_cls: 0.01682  loss_box_reg: 0.04754  loss_mask: 0.07349  loss_rpn_cls: 0.0004736  loss_rpn_loc: 0.003527  lr: 0.002  max_mem: 7203M
[07/26 16:52:53] d2.utils.events INFO:  eta: 0:30:02  iter: 5119  total_loss: 0.1348  loss_cls: 0.01843  loss_box_reg: 0.04644  loss_mask: 0.07247  loss_rpn_cls: 0.0003253  loss_rpn_loc: 0.003022  lr: 0.002  max_mem: 7203M
[07/26 16:53:08] d2.utils.events INFO:  eta: 0:29:26  iter: 5139  total_loss: 0.1376  loss_cls: 0.01691  loss_box_reg: 0.0428  loss_mask: 0.07573  loss_rpn_cls: 0.000389  loss_rpn_loc: 0.003061  lr: 0.002  max_mem: 7203M
[07/26 16:53:23] d2.utils.events INFO:  eta: 0:29:20  iter: 5159  total_loss: 0.1333  loss_cls: 0.01731  loss_box_reg: 0.04323  loss_mask: 0.06717  loss_rpn_cls: 0.0004536  loss_rpn_loc: 0.003292  lr: 0.002  max_mem: 7203M
[07/26 16:53:38] d2.utils.events INFO:  eta: 0:28:57  iter: 5179  total_loss: 0.1394  loss_cls: 0.01812  loss_box_reg: 0.04265  loss_mask: 0.07385  loss_rpn_cls: 0.0004897  loss_rpn_loc: 0.003411  lr: 0.002  max_mem: 7203M
[07/26 16:53:53] d2.utils.events INFO:  eta: 0:28:40  iter: 5199  total_loss: 0.1317  loss_cls: 0.01769  loss_box_reg: 0.04377  loss_mask: 0.06643  loss_rpn_cls: 0.0003205  loss_rpn_loc: 0.003297  lr: 0.002  max_mem: 7203M
[07/26 16:54:08] d2.utils.events INFO:  eta: 0:28:31  iter: 5219  total_loss: 0.1329  loss_cls: 0.0166  loss_box_reg: 0.04197  loss_mask: 0.06936  loss_rpn_cls: 0.0003162  loss_rpn_loc: 0.003077  lr: 0.002  max_mem: 7203M
[07/26 16:54:23] d2.utils.events INFO:  eta: 0:28:09  iter: 5239  total_loss: 0.1288  loss_cls: 0.01733  loss_box_reg: 0.04223  loss_mask: 0.06645  loss_rpn_cls: 0.0002711  loss_rpn_loc: 0.003101  lr: 0.002  max_mem: 7203M
[07/26 16:54:38] d2.utils.events INFO:  eta: 0:28:06  iter: 5259  total_loss: 0.1356  loss_cls: 0.01726  loss_box_reg: 0.04306  loss_mask: 0.06796  loss_rpn_cls: 0.0002749  loss_rpn_loc: 0.003234  lr: 0.002  max_mem: 7203M
[07/26 16:54:53] d2.utils.events INFO:  eta: 0:27:43  iter: 5279  total_loss: 0.1323  loss_cls: 0.01815  loss_box_reg: 0.04266  loss_mask: 0.06731  loss_rpn_cls: 0.0003269  loss_rpn_loc: 0.003103  lr: 0.002  max_mem: 7203M
[07/26 16:55:08] d2.utils.events INFO:  eta: 0:27:17  iter: 5299  total_loss: 0.1338  loss_cls: 0.01717  loss_box_reg: 0.04382  loss_mask: 0.06866  loss_rpn_cls: 0.0002912  loss_rpn_loc: 0.003156  lr: 0.002  max_mem: 7203M
[07/26 16:55:22] d2.utils.events INFO:  eta: 0:27:00  iter: 5319  total_loss: 0.1302  loss_cls: 0.01669  loss_box_reg: 0.03813  loss_mask: 0.0712  loss_rpn_cls: 0.0003009  loss_rpn_loc: 0.003037  lr: 0.002  max_mem: 7203M
[07/26 16:55:37] d2.utils.events INFO:  eta: 0:27:08  iter: 5339  total_loss: 0.1352  loss_cls: 0.01773  loss_box_reg: 0.04507  loss_mask: 0.06706  loss_rpn_cls: 0.0004319  loss_rpn_loc: 0.00328  lr: 0.002  max_mem: 7203M
[07/26 16:55:52] d2.utils.events INFO:  eta: 0:26:32  iter: 5359  total_loss: 0.1364  loss_cls: 0.01747  loss_box_reg: 0.04211  loss_mask: 0.07156  loss_rpn_cls: 0.0002902  loss_rpn_loc: 0.003292  lr: 0.002  max_mem: 7203M
[07/26 16:56:07] d2.utils.events INFO:  eta: 0:26:43  iter: 5379  total_loss: 0.1242  loss_cls: 0.0182  loss_box_reg: 0.04274  loss_mask: 0.06324  loss_rpn_cls: 0.0002977  loss_rpn_loc: 0.003083  lr: 0.002  max_mem: 7203M
[07/26 16:56:22] d2.utils.events INFO:  eta: 0:26:06  iter: 5399  total_loss: 0.1437  loss_cls: 0.01697  loss_box_reg: 0.04595  loss_mask: 0.07623  loss_rpn_cls: 0.0005198  loss_rpn_loc: 0.00353  lr: 0.002  max_mem: 7203M
[07/26 16:56:38] d2.utils.events INFO:  eta: 0:26:21  iter: 5419  total_loss: 0.1448  loss_cls: 0.01787  loss_box_reg: 0.04404  loss_mask: 0.07653  loss_rpn_cls: 0.000626  loss_rpn_loc: 0.00344  lr: 0.002  max_mem: 7203M
[07/26 16:56:53] d2.utils.events INFO:  eta: 0:25:50  iter: 5439  total_loss: 0.1296  loss_cls: 0.01718  loss_box_reg: 0.03984  loss_mask: 0.06924  loss_rpn_cls: 0.0005693  loss_rpn_loc: 0.002939  lr: 0.002  max_mem: 7203M
[07/26 16:57:08] d2.utils.events INFO:  eta: 0:25:40  iter: 5459  total_loss: 0.1332  loss_cls: 0.0179  loss_box_reg: 0.04341  loss_mask: 0.06682  loss_rpn_cls: 0.0003535  loss_rpn_loc: 0.003133  lr: 0.002  max_mem: 7203M
[07/26 16:57:23] d2.utils.events INFO:  eta: 0:25:38  iter: 5479  total_loss: 0.1332  loss_cls: 0.01721  loss_box_reg: 0.04382  loss_mask: 0.06552  loss_rpn_cls: 0.0003477  loss_rpn_loc: 0.003026  lr: 0.002  max_mem: 7203M
[07/26 16:57:38] d2.utils.events INFO:  eta: 0:25:04  iter: 5499  total_loss: 0.1309  loss_cls: 0.01739  loss_box_reg: 0.04396  loss_mask: 0.06616  loss_rpn_cls: 0.0002812  loss_rpn_loc: 0.002839  lr: 0.002  max_mem: 7203M
[07/26 16:57:53] d2.utils.events INFO:  eta: 0:24:59  iter: 5519  total_loss: 0.1353  loss_cls: 0.01612  loss_box_reg: 0.04283  loss_mask: 0.06822  loss_rpn_cls: 0.0002772  loss_rpn_loc: 0.003094  lr: 0.002  max_mem: 7203M
[07/26 16:58:08] d2.utils.events INFO:  eta: 0:24:28  iter: 5539  total_loss: 0.1233  loss_cls: 0.01627  loss_box_reg: 0.04001  loss_mask: 0.06498  loss_rpn_cls: 0.0002156  loss_rpn_loc: 0.003114  lr: 0.002  max_mem: 7203M
[07/26 16:58:23] d2.utils.events INFO:  eta: 0:24:24  iter: 5559  total_loss: 0.1276  loss_cls: 0.01713  loss_box_reg: 0.04017  loss_mask: 0.06564  loss_rpn_cls: 0.0003325  loss_rpn_loc: 0.003226  lr: 0.002  max_mem: 7203M
[07/26 16:58:38] d2.utils.events INFO:  eta: 0:23:56  iter: 5579  total_loss: 0.1359  loss_cls: 0.01726  loss_box_reg: 0.04436  loss_mask: 0.07308  loss_rpn_cls: 0.0003012  loss_rpn_loc: 0.002867  lr: 0.002  max_mem: 7203M
[07/26 16:58:53] d2.utils.events INFO:  eta: 0:23:46  iter: 5599  total_loss: 0.1318  loss_cls: 0.01622  loss_box_reg: 0.04199  loss_mask: 0.07027  loss_rpn_cls: 0.0003203  loss_rpn_loc: 0.003358  lr: 0.002  max_mem: 7203M
[07/26 16:59:08] d2.utils.events INFO:  eta: 0:23:30  iter: 5619  total_loss: 0.1383  loss_cls: 0.01711  loss_box_reg: 0.04594  loss_mask: 0.07307  loss_rpn_cls: 0.0003332  loss_rpn_loc: 0.003124  lr: 0.002  max_mem: 7203M
[07/26 16:59:23] d2.utils.events INFO:  eta: 0:23:14  iter: 5639  total_loss: 0.1263  loss_cls: 0.01638  loss_box_reg: 0.04152  loss_mask: 0.06386  loss_rpn_cls: 0.0001918  loss_rpn_loc: 0.002982  lr: 0.002  max_mem: 7203M
[07/26 16:59:38] d2.utils.events INFO:  eta: 0:23:12  iter: 5659  total_loss: 0.1287  loss_cls: 0.01719  loss_box_reg: 0.04249  loss_mask: 0.07039  loss_rpn_cls: 0.0002763  loss_rpn_loc: 0.002928  lr: 0.002  max_mem: 7203M
[07/26 16:59:53] d2.utils.events INFO:  eta: 0:22:41  iter: 5679  total_loss: 0.1313  loss_cls: 0.01897  loss_box_reg: 0.04431  loss_mask: 0.06679  loss_rpn_cls: 0.000391  loss_rpn_loc: 0.00303  lr: 0.002  max_mem: 7203M
[07/26 17:00:08] d2.utils.events INFO:  eta: 0:22:24  iter: 5699  total_loss: 0.1339  loss_cls: 0.01721  loss_box_reg: 0.04592  loss_mask: 0.06855  loss_rpn_cls: 0.0002913  loss_rpn_loc: 0.002857  lr: 0.002  max_mem: 7203M
[07/26 17:00:23] d2.utils.events INFO:  eta: 0:22:14  iter: 5719  total_loss: 0.128  loss_cls: 0.01649  loss_box_reg: 0.0418  loss_mask: 0.06476  loss_rpn_cls: 0.0002527  loss_rpn_loc: 0.002838  lr: 0.002  max_mem: 7203M
[07/26 17:00:38] d2.utils.events INFO:  eta: 0:22:13  iter: 5739  total_loss: 0.1271  loss_cls: 0.0177  loss_box_reg: 0.04256  loss_mask: 0.06663  loss_rpn_cls: 0.0004275  loss_rpn_loc: 0.002938  lr: 0.002  max_mem: 7203M
[07/26 17:00:53] d2.utils.events INFO:  eta: 0:21:52  iter: 5759  total_loss: 0.1301  loss_cls: 0.01734  loss_box_reg: 0.04192  loss_mask: 0.06728  loss_rpn_cls: 0.0003742  loss_rpn_loc: 0.003025  lr: 0.002  max_mem: 7203M
[07/26 17:01:09] d2.utils.events INFO:  eta: 0:21:38  iter: 5779  total_loss: 0.1287  loss_cls: 0.01664  loss_box_reg: 0.04219  loss_mask: 0.06417  loss_rpn_cls: 0.0003427  loss_rpn_loc: 0.002753  lr: 0.002  max_mem: 7203M
[07/26 17:01:24] d2.utils.events INFO:  eta: 0:21:10  iter: 5799  total_loss: 0.1252  loss_cls: 0.01668  loss_box_reg: 0.04105  loss_mask: 0.06488  loss_rpn_cls: 0.000318  loss_rpn_loc: 0.00348  lr: 0.002  max_mem: 7203M
[07/26 17:01:39] d2.utils.events INFO:  eta: 0:21:06  iter: 5819  total_loss: 0.1257  loss_cls: 0.01775  loss_box_reg: 0.03983  loss_mask: 0.06491  loss_rpn_cls: 0.0002907  loss_rpn_loc: 0.003261  lr: 0.002  max_mem: 7203M
[07/26 17:01:54] d2.utils.events INFO:  eta: 0:20:42  iter: 5839  total_loss: 0.1292  loss_cls: 0.01644  loss_box_reg: 0.04197  loss_mask: 0.06651  loss_rpn_cls: 0.0002759  loss_rpn_loc: 0.003424  lr: 0.002  max_mem: 7203M
[07/26 17:02:09] d2.utils.events INFO:  eta: 0:20:33  iter: 5859  total_loss: 0.1227  loss_cls: 0.01546  loss_box_reg: 0.03965  loss_mask: 0.06225  loss_rpn_cls: 0.0002785  loss_rpn_loc: 0.002742  lr: 0.002  max_mem: 7203M
[07/26 17:02:24] d2.utils.events INFO:  eta: 0:20:17  iter: 5879  total_loss: 0.1317  loss_cls: 0.01596  loss_box_reg: 0.03997  loss_mask: 0.0666  loss_rpn_cls: 0.0003073  loss_rpn_loc: 0.002688  lr: 0.002  max_mem: 7203M
[07/26 17:02:39] d2.utils.events INFO:  eta: 0:20:03  iter: 5899  total_loss: 0.1275  loss_cls: 0.01723  loss_box_reg: 0.04195  loss_mask: 0.06447  loss_rpn_cls: 0.0003246  loss_rpn_loc: 0.002946  lr: 0.002  max_mem: 7203M
[07/26 17:02:54] d2.utils.events INFO:  eta: 0:19:40  iter: 5919  total_loss: 0.1278  loss_cls: 0.01632  loss_box_reg: 0.04166  loss_mask: 0.06893  loss_rpn_cls: 0.0002786  loss_rpn_loc: 0.002741  lr: 0.002  max_mem: 7203M
[07/26 17:03:09] d2.utils.events INFO:  eta: 0:19:35  iter: 5939  total_loss: 0.1185  loss_cls: 0.01706  loss_box_reg: 0.03828  loss_mask: 0.06047  loss_rpn_cls: 0.0003052  loss_rpn_loc: 0.002438  lr: 0.002  max_mem: 7203M
[07/26 17:03:24] d2.utils.events INFO:  eta: 0:19:16  iter: 5959  total_loss: 0.1243  loss_cls: 0.01594  loss_box_reg: 0.03955  loss_mask: 0.06471  loss_rpn_cls: 0.0002439  loss_rpn_loc: 0.002906  lr: 0.002  max_mem: 7203M
[07/26 17:03:39] d2.utils.events INFO:  eta: 0:18:58  iter: 5979  total_loss: 0.1376  loss_cls: 0.01766  loss_box_reg: 0.04369  loss_mask: 0.06971  loss_rpn_cls: 0.0002607  loss_rpn_loc: 0.003372  lr: 0.002  max_mem: 7203M
[07/26 17:03:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/26 17:03:54] d2.data.common INFO: Serializing 45 elements to byte tensors and concatenating them all ...
[07/26 17:03:54] d2.data.common INFO: Serialized dataset takes 0.06 MiB
[07/26 17:03:54] d2.evaluation.evaluator INFO: Start inference on 45 batches
[07/26 17:03:55] d2.evaluation.evaluator INFO: Inference done 11/45. Dataloading: 0.0008 s/iter. Inference: 0.0582 s/iter. Eval: 0.0003 s/iter. Total: 0.0593 s/iter. ETA=0:00:02
[07/26 17:03:57] d2.evaluation.evaluator INFO: Total inference time: 0:00:02.426551 (0.060664 s / iter per device, on 1 devices)
[07/26 17:03:57] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.057579 s / iter per device, on 1 devices)
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Saving results to output/with_augmentation/inference/for_detectron_synth_val/coco_instances_results.json
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.965 | 2.475  | 0.743  | 0.000 | 0.965 | 0.000 |
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 1.931 |
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 17:03:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.213 | 2.475  | 0.743  | 0.000 | 1.213 | 0.000 |
[07/26 17:03:57] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 2.426 |
[07/26 17:03:57] detectron2 INFO: Evaluation results for for_detectron_synth_val in csv format:
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: 0.9653,2.4752,0.7426,0.0000,0.9653,0.0000
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: Task: segm
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 17:03:57] d2.evaluation.testing INFO: copypaste: 1.2129,2.4752,0.7426,0.0000,1.2129,0.0000
[07/26 17:03:57] d2.utils.events INFO:  eta: 0:22:54  iter: 5999  total_loss: 0.1214  loss_cls: 0.01628  loss_box_reg: 0.03845  loss_mask: 0.0646  loss_rpn_cls: 0.0002505  loss_rpn_loc: 0.002631  lr: 0.002  max_mem: 7203M
[07/26 17:04:12] d2.utils.events INFO:  eta: 0:18:22  iter: 6019  total_loss: 0.1439  loss_cls: 0.01964  loss_box_reg: 0.04481  loss_mask: 0.0707  loss_rpn_cls: 0.0004636  loss_rpn_loc: 0.003298  lr: 0.002  max_mem: 7203M
[07/26 17:04:27] d2.utils.events INFO:  eta: 0:18:01  iter: 6039  total_loss: 0.1608  loss_cls: 0.02057  loss_box_reg: 0.04929  loss_mask: 0.08335  loss_rpn_cls: 0.0003502  loss_rpn_loc: 0.003472  lr: 0.002  max_mem: 7203M
[07/26 17:04:42] d2.utils.events INFO:  eta: 0:17:55  iter: 6059  total_loss: 0.1602  loss_cls: 0.01974  loss_box_reg: 0.0493  loss_mask: 0.08344  loss_rpn_cls: 0.0005121  loss_rpn_loc: 0.003845  lr: 0.002  max_mem: 7203M
[07/26 17:04:57] d2.utils.events INFO:  eta: 0:17:39  iter: 6079  total_loss: 0.1396  loss_cls: 0.01991  loss_box_reg: 0.04602  loss_mask: 0.07049  loss_rpn_cls: 0.0003985  loss_rpn_loc: 0.003676  lr: 0.002  max_mem: 7203M
[07/26 17:05:12] d2.utils.events INFO:  eta: 0:17:29  iter: 6099  total_loss: 0.1386  loss_cls: 0.01674  loss_box_reg: 0.0423  loss_mask: 0.07456  loss_rpn_cls: 0.0004042  loss_rpn_loc: 0.003276  lr: 0.002  max_mem: 7203M
[07/26 17:05:27] d2.utils.events INFO:  eta: 0:17:12  iter: 6119  total_loss: 0.1376  loss_cls: 0.01817  loss_box_reg: 0.04713  loss_mask: 0.06873  loss_rpn_cls: 0.0003977  loss_rpn_loc: 0.003292  lr: 0.002  max_mem: 7203M
[07/26 17:05:42] d2.utils.events INFO:  eta: 0:17:03  iter: 6139  total_loss: 0.1227  loss_cls: 0.01693  loss_box_reg: 0.04101  loss_mask: 0.06598  loss_rpn_cls: 0.0002289  loss_rpn_loc: 0.002962  lr: 0.002  max_mem: 7203M
[07/26 17:05:57] d2.utils.events INFO:  eta: 0:16:43  iter: 6159  total_loss: 0.1332  loss_cls: 0.0169  loss_box_reg: 0.04077  loss_mask: 0.07019  loss_rpn_cls: 0.0004201  loss_rpn_loc: 0.003061  lr: 0.002  max_mem: 7203M
[07/26 17:06:12] d2.utils.events INFO:  eta: 0:16:28  iter: 6179  total_loss: 0.1585  loss_cls: 0.02166  loss_box_reg: 0.04839  loss_mask: 0.08101  loss_rpn_cls: 0.0003102  loss_rpn_loc: 0.003467  lr: 0.002  max_mem: 7203M
[07/26 17:06:27] d2.utils.events INFO:  eta: 0:16:09  iter: 6199  total_loss: 0.2529  loss_cls: 0.03943  loss_box_reg: 0.07154  loss_mask: 0.1215  loss_rpn_cls: 0.001419  loss_rpn_loc: 0.005205  lr: 0.002  max_mem: 7203M
[07/26 17:06:41] d2.utils.events INFO:  eta: 0:15:51  iter: 6219  total_loss: 0.1764  loss_cls: 0.02418  loss_box_reg: 0.05202  loss_mask: 0.09094  loss_rpn_cls: 0.001015  loss_rpn_loc: 0.004324  lr: 0.002  max_mem: 7203M
[07/26 17:06:56] d2.utils.events INFO:  eta: 0:15:33  iter: 6239  total_loss: 0.1559  loss_cls: 0.02039  loss_box_reg: 0.0485  loss_mask: 0.08052  loss_rpn_cls: 0.0003672  loss_rpn_loc: 0.003378  lr: 0.002  max_mem: 7203M
[07/26 17:07:11] d2.utils.events INFO:  eta: 0:15:25  iter: 6259  total_loss: 0.138  loss_cls: 0.01778  loss_box_reg: 0.0429  loss_mask: 0.06811  loss_rpn_cls: 0.0004116  loss_rpn_loc: 0.003859  lr: 0.002  max_mem: 7203M
[07/26 17:07:26] d2.utils.events INFO:  eta: 0:15:15  iter: 6279  total_loss: 0.1387  loss_cls: 0.0179  loss_box_reg: 0.04228  loss_mask: 0.07451  loss_rpn_cls: 0.0004541  loss_rpn_loc: 0.003297  lr: 0.002  max_mem: 7203M
[07/26 17:07:41] d2.utils.events INFO:  eta: 0:14:52  iter: 6299  total_loss: 0.1314  loss_cls: 0.01749  loss_box_reg: 0.04127  loss_mask: 0.07057  loss_rpn_cls: 0.0003225  loss_rpn_loc: 0.002956  lr: 0.002  max_mem: 7203M
[07/26 17:07:56] d2.utils.events INFO:  eta: 0:14:37  iter: 6319  total_loss: 0.124  loss_cls: 0.01648  loss_box_reg: 0.03933  loss_mask: 0.07142  loss_rpn_cls: 0.0003099  loss_rpn_loc: 0.002789  lr: 0.002  max_mem: 7203M
[07/26 17:08:11] d2.utils.events INFO:  eta: 0:14:35  iter: 6339  total_loss: 0.1288  loss_cls: 0.01772  loss_box_reg: 0.04213  loss_mask: 0.06241  loss_rpn_cls: 0.0004186  loss_rpn_loc: 0.003319  lr: 0.002  max_mem: 7203M
[07/26 17:08:26] d2.utils.events INFO:  eta: 0:14:12  iter: 6359  total_loss: 0.1344  loss_cls: 0.01704  loss_box_reg: 0.04347  loss_mask: 0.06859  loss_rpn_cls: 0.0004417  loss_rpn_loc: 0.003612  lr: 0.002  max_mem: 7203M
[07/26 17:08:41] d2.utils.events INFO:  eta: 0:14:03  iter: 6379  total_loss: 0.1295  loss_cls: 0.01762  loss_box_reg: 0.04187  loss_mask: 0.06357  loss_rpn_cls: 0.0003301  loss_rpn_loc: 0.002874  lr: 0.002  max_mem: 7203M
[07/26 17:08:56] d2.utils.events INFO:  eta: 0:13:37  iter: 6399  total_loss: 0.1254  loss_cls: 0.01595  loss_box_reg: 0.04238  loss_mask: 0.06483  loss_rpn_cls: 0.0002368  loss_rpn_loc: 0.003226  lr: 0.002  max_mem: 7203M
[07/26 17:09:11] d2.utils.events INFO:  eta: 0:13:25  iter: 6419  total_loss: 0.1271  loss_cls: 0.0166  loss_box_reg: 0.0416  loss_mask: 0.06964  loss_rpn_cls: 0.0002427  loss_rpn_loc: 0.0029  lr: 0.002  max_mem: 7203M
[07/26 17:09:26] d2.utils.events INFO:  eta: 0:13:10  iter: 6439  total_loss: 0.1274  loss_cls: 0.01526  loss_box_reg: 0.03718  loss_mask: 0.0668  loss_rpn_cls: 0.0003439  loss_rpn_loc: 0.003198  lr: 0.002  max_mem: 7203M
[07/26 17:09:41] d2.utils.events INFO:  eta: 0:12:58  iter: 6459  total_loss: 0.1211  loss_cls: 0.01472  loss_box_reg: 0.03768  loss_mask: 0.0663  loss_rpn_cls: 0.0003175  loss_rpn_loc: 0.003045  lr: 0.002  max_mem: 7203M
[07/26 17:09:56] d2.utils.events INFO:  eta: 0:12:36  iter: 6479  total_loss: 0.1253  loss_cls: 0.01681  loss_box_reg: 0.0423  loss_mask: 0.06681  loss_rpn_cls: 0.0002453  loss_rpn_loc: 0.002859  lr: 0.002  max_mem: 7203M
[07/26 17:10:10] d2.utils.events INFO:  eta: 0:12:21  iter: 6499  total_loss: 0.1273  loss_cls: 0.01576  loss_box_reg: 0.03876  loss_mask: 0.07106  loss_rpn_cls: 0.0002614  loss_rpn_loc: 0.003181  lr: 0.002  max_mem: 7203M
[07/26 17:10:25] d2.utils.events INFO:  eta: 0:12:17  iter: 6519  total_loss: 0.1287  loss_cls: 0.01666  loss_box_reg: 0.04139  loss_mask: 0.06479  loss_rpn_cls: 0.0002405  loss_rpn_loc: 0.00308  lr: 0.002  max_mem: 7203M
[07/26 17:10:40] d2.utils.events INFO:  eta: 0:12:00  iter: 6539  total_loss: 0.1212  loss_cls: 0.01486  loss_box_reg: 0.03581  loss_mask: 0.06746  loss_rpn_cls: 0.0002656  loss_rpn_loc: 0.002815  lr: 0.002  max_mem: 7203M
[07/26 17:10:55] d2.utils.events INFO:  eta: 0:11:43  iter: 6559  total_loss: 0.122  loss_cls: 0.01517  loss_box_reg: 0.03957  loss_mask: 0.06411  loss_rpn_cls: 0.0003338  loss_rpn_loc: 0.003095  lr: 0.002  max_mem: 7203M
[07/26 17:11:10] d2.utils.events INFO:  eta: 0:11:34  iter: 6579  total_loss: 0.1226  loss_cls: 0.01582  loss_box_reg: 0.03649  loss_mask: 0.0631  loss_rpn_cls: 0.0004341  loss_rpn_loc: 0.002642  lr: 0.002  max_mem: 7203M
[07/26 17:11:25] d2.utils.events INFO:  eta: 0:11:14  iter: 6599  total_loss: 0.1116  loss_cls: 0.01444  loss_box_reg: 0.03436  loss_mask: 0.0613  loss_rpn_cls: 0.0002944  loss_rpn_loc: 0.002636  lr: 0.002  max_mem: 7203M
[07/26 17:11:41] d2.utils.events INFO:  eta: 0:11:05  iter: 6619  total_loss: 0.1192  loss_cls: 0.01549  loss_box_reg: 0.0377  loss_mask: 0.06198  loss_rpn_cls: 0.000202  loss_rpn_loc: 0.002874  lr: 0.002  max_mem: 7203M
[07/26 17:11:56] d2.utils.events INFO:  eta: 0:10:44  iter: 6639  total_loss: 0.1163  loss_cls: 0.01472  loss_box_reg: 0.03519  loss_mask: 0.06305  loss_rpn_cls: 0.0002823  loss_rpn_loc: 0.003118  lr: 0.002  max_mem: 7203M
[07/26 17:12:11] d2.utils.events INFO:  eta: 0:10:35  iter: 6659  total_loss: 0.1213  loss_cls: 0.0155  loss_box_reg: 0.04107  loss_mask: 0.06505  loss_rpn_cls: 0.0002743  loss_rpn_loc: 0.00337  lr: 0.002  max_mem: 7203M
[07/26 17:12:26] d2.utils.events INFO:  eta: 0:10:10  iter: 6679  total_loss: 0.1186  loss_cls: 0.01622  loss_box_reg: 0.03365  loss_mask: 0.0669  loss_rpn_cls: 0.0005085  loss_rpn_loc: 0.003132  lr: 0.002  max_mem: 7203M
[07/26 17:12:41] d2.utils.events INFO:  eta: 0:10:03  iter: 6699  total_loss: 0.1191  loss_cls: 0.01679  loss_box_reg: 0.03851  loss_mask: 0.06316  loss_rpn_cls: 0.0002801  loss_rpn_loc: 0.002878  lr: 0.002  max_mem: 7203M
[07/26 17:12:56] d2.utils.events INFO:  eta: 0:09:43  iter: 6719  total_loss: 0.1256  loss_cls: 0.01562  loss_box_reg: 0.03819  loss_mask: 0.06561  loss_rpn_cls: 0.0003294  loss_rpn_loc: 0.002976  lr: 0.002  max_mem: 7203M
[07/26 17:13:11] d2.utils.events INFO:  eta: 0:09:30  iter: 6739  total_loss: 0.1216  loss_cls: 0.01531  loss_box_reg: 0.0367  loss_mask: 0.06207  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.002781  lr: 0.002  max_mem: 7203M
[07/26 17:13:26] d2.utils.events INFO:  eta: 0:09:10  iter: 6759  total_loss: 0.1246  loss_cls: 0.01513  loss_box_reg: 0.0393  loss_mask: 0.06689  loss_rpn_cls: 0.000326  loss_rpn_loc: 0.002907  lr: 0.002  max_mem: 7203M
[07/26 17:13:41] d2.utils.events INFO:  eta: 0:09:00  iter: 6779  total_loss: 0.1157  loss_cls: 0.01575  loss_box_reg: 0.03644  loss_mask: 0.0619  loss_rpn_cls: 0.0002155  loss_rpn_loc: 0.002658  lr: 0.002  max_mem: 7203M
[07/26 17:13:56] d2.utils.events INFO:  eta: 0:08:46  iter: 6799  total_loss: 0.1279  loss_cls: 0.01499  loss_box_reg: 0.04066  loss_mask: 0.06466  loss_rpn_cls: 0.0005324  loss_rpn_loc: 0.003238  lr: 0.002  max_mem: 7203M
[07/26 17:14:11] d2.utils.events INFO:  eta: 0:08:35  iter: 6819  total_loss: 0.1199  loss_cls: 0.01494  loss_box_reg: 0.03753  loss_mask: 0.06081  loss_rpn_cls: 0.0002974  loss_rpn_loc: 0.002937  lr: 0.002  max_mem: 7203M
[07/26 17:14:26] d2.utils.events INFO:  eta: 0:08:09  iter: 6839  total_loss: 0.1122  loss_cls: 0.01292  loss_box_reg: 0.03513  loss_mask: 0.06037  loss_rpn_cls: 0.000217  loss_rpn_loc: 0.002701  lr: 0.002  max_mem: 7203M
[07/26 17:14:41] d2.utils.events INFO:  eta: 0:08:02  iter: 6859  total_loss: 0.1261  loss_cls: 0.01532  loss_box_reg: 0.03842  loss_mask: 0.06503  loss_rpn_cls: 0.0002397  loss_rpn_loc: 0.002685  lr: 0.002  max_mem: 7203M
[07/26 17:14:56] d2.utils.events INFO:  eta: 0:07:41  iter: 6879  total_loss: 0.117  loss_cls: 0.01529  loss_box_reg: 0.03638  loss_mask: 0.06226  loss_rpn_cls: 0.0002026  loss_rpn_loc: 0.002669  lr: 0.002  max_mem: 7203M
[07/26 17:15:11] d2.utils.events INFO:  eta: 0:07:34  iter: 6899  total_loss: 0.1238  loss_cls: 0.01579  loss_box_reg: 0.04146  loss_mask: 0.06462  loss_rpn_cls: 0.0005054  loss_rpn_loc: 0.002778  lr: 0.002  max_mem: 7203M
[07/26 17:15:26] d2.utils.events INFO:  eta: 0:07:20  iter: 6919  total_loss: 0.1259  loss_cls: 0.01709  loss_box_reg: 0.03843  loss_mask: 0.06545  loss_rpn_cls: 0.0002978  loss_rpn_loc: 0.002923  lr: 0.002  max_mem: 7203M
[07/26 17:15:41] d2.utils.events INFO:  eta: 0:06:58  iter: 6939  total_loss: 0.1148  loss_cls: 0.01531  loss_box_reg: 0.03633  loss_mask: 0.06165  loss_rpn_cls: 0.0002536  loss_rpn_loc: 0.003236  lr: 0.002  max_mem: 7203M
[07/26 17:15:56] d2.utils.events INFO:  eta: 0:06:44  iter: 6959  total_loss: 0.1115  loss_cls: 0.01472  loss_box_reg: 0.0343  loss_mask: 0.0595  loss_rpn_cls: 0.000237  loss_rpn_loc: 0.002581  lr: 0.002  max_mem: 7203M
[07/26 17:16:11] d2.utils.events INFO:  eta: 0:06:30  iter: 6979  total_loss: 0.1129  loss_cls: 0.01422  loss_box_reg: 0.03716  loss_mask: 0.05937  loss_rpn_cls: 0.0002094  loss_rpn_loc: 0.002459  lr: 0.002  max_mem: 7203M
[07/26 17:16:26] d2.utils.events INFO:  eta: 0:06:13  iter: 6999  total_loss: 0.1167  loss_cls: 0.01585  loss_box_reg: 0.03609  loss_mask: 0.061  loss_rpn_cls: 0.0002584  loss_rpn_loc: 0.002447  lr: 0.002  max_mem: 7203M
[07/26 17:16:41] d2.utils.events INFO:  eta: 0:06:00  iter: 7019  total_loss: 0.1194  loss_cls: 0.01655  loss_box_reg: 0.03876  loss_mask: 0.05977  loss_rpn_cls: 0.0002478  loss_rpn_loc: 0.002825  lr: 0.002  max_mem: 7203M
[07/26 17:16:56] d2.utils.events INFO:  eta: 0:05:47  iter: 7039  total_loss: 0.1195  loss_cls: 0.01508  loss_box_reg: 0.03735  loss_mask: 0.06278  loss_rpn_cls: 0.000251  loss_rpn_loc: 0.002621  lr: 0.002  max_mem: 7203M
[07/26 17:17:11] d2.utils.events INFO:  eta: 0:05:30  iter: 7059  total_loss: 0.1089  loss_cls: 0.01418  loss_box_reg: 0.03587  loss_mask: 0.05872  loss_rpn_cls: 0.0002801  loss_rpn_loc: 0.00267  lr: 0.002  max_mem: 7203M
[07/26 17:17:26] d2.utils.events INFO:  eta: 0:05:19  iter: 7079  total_loss: 0.1153  loss_cls: 0.01546  loss_box_reg: 0.0361  loss_mask: 0.06177  loss_rpn_cls: 0.0001545  loss_rpn_loc: 0.002566  lr: 0.002  max_mem: 7203M
[07/26 17:17:41] d2.utils.events INFO:  eta: 0:05:01  iter: 7099  total_loss: 0.1187  loss_cls: 0.01582  loss_box_reg: 0.03914  loss_mask: 0.06038  loss_rpn_cls: 0.0002669  loss_rpn_loc: 0.002721  lr: 0.002  max_mem: 7203M
[07/26 17:17:56] d2.utils.events INFO:  eta: 0:04:43  iter: 7119  total_loss: 0.1139  loss_cls: 0.01432  loss_box_reg: 0.03561  loss_mask: 0.06169  loss_rpn_cls: 0.0002187  loss_rpn_loc: 0.002729  lr: 0.002  max_mem: 7203M
[07/26 17:18:11] d2.utils.events INFO:  eta: 0:04:32  iter: 7139  total_loss: 0.1168  loss_cls: 0.01419  loss_box_reg: 0.03759  loss_mask: 0.0609  loss_rpn_cls: 0.0002615  loss_rpn_loc: 0.00236  lr: 0.002  max_mem: 7203M
[07/26 17:18:26] d2.utils.events INFO:  eta: 0:04:13  iter: 7159  total_loss: 0.1148  loss_cls: 0.01405  loss_box_reg: 0.03528  loss_mask: 0.06231  loss_rpn_cls: 0.0002905  loss_rpn_loc: 0.002917  lr: 0.002  max_mem: 7203M
[07/26 17:18:41] d2.utils.events INFO:  eta: 0:03:58  iter: 7179  total_loss: 0.1097  loss_cls: 0.01381  loss_box_reg: 0.03586  loss_mask: 0.05882  loss_rpn_cls: 0.0001764  loss_rpn_loc: 0.002582  lr: 0.002  max_mem: 7203M
[07/26 17:18:56] d2.utils.events INFO:  eta: 0:03:44  iter: 7199  total_loss: 0.1114  loss_cls: 0.01482  loss_box_reg: 0.03514  loss_mask: 0.05783  loss_rpn_cls: 0.0001822  loss_rpn_loc: 0.002623  lr: 0.002  max_mem: 7203M
[07/26 17:19:11] d2.utils.events INFO:  eta: 0:03:30  iter: 7219  total_loss: 0.1122  loss_cls: 0.01372  loss_box_reg: 0.03387  loss_mask: 0.05963  loss_rpn_cls: 0.0002443  loss_rpn_loc: 0.002789  lr: 0.002  max_mem: 7203M
[07/26 17:19:26] d2.utils.events INFO:  eta: 0:03:13  iter: 7239  total_loss: 0.1084  loss_cls: 0.0132  loss_box_reg: 0.03281  loss_mask: 0.06069  loss_rpn_cls: 0.0002757  loss_rpn_loc: 0.002754  lr: 0.002  max_mem: 7203M
[07/26 17:19:41] d2.utils.events INFO:  eta: 0:02:58  iter: 7259  total_loss: 0.1104  loss_cls: 0.01217  loss_box_reg: 0.0362  loss_mask: 0.05727  loss_rpn_cls: 0.000199  loss_rpn_loc: 0.002622  lr: 0.002  max_mem: 7203M
[07/26 17:19:56] d2.utils.events INFO:  eta: 0:02:44  iter: 7279  total_loss: 0.1049  loss_cls: 0.0129  loss_box_reg: 0.03231  loss_mask: 0.05659  loss_rpn_cls: 0.0001892  loss_rpn_loc: 0.002598  lr: 0.002  max_mem: 7203M
[07/26 17:20:11] d2.utils.events INFO:  eta: 0:02:30  iter: 7299  total_loss: 0.1148  loss_cls: 0.01454  loss_box_reg: 0.03615  loss_mask: 0.06477  loss_rpn_cls: 0.0001812  loss_rpn_loc: 0.003031  lr: 0.002  max_mem: 7203M
[07/26 17:20:26] d2.utils.events INFO:  eta: 0:02:14  iter: 7319  total_loss: 0.1233  loss_cls: 0.01546  loss_box_reg: 0.04062  loss_mask: 0.06103  loss_rpn_cls: 0.000212  loss_rpn_loc: 0.002719  lr: 0.002  max_mem: 7203M
[07/26 17:20:41] d2.utils.events INFO:  eta: 0:01:59  iter: 7339  total_loss: 0.1162  loss_cls: 0.01507  loss_box_reg: 0.03691  loss_mask: 0.06012  loss_rpn_cls: 0.00019  loss_rpn_loc: 0.002661  lr: 0.002  max_mem: 7203M
[07/26 17:20:56] d2.utils.events INFO:  eta: 0:01:44  iter: 7359  total_loss: 0.1074  loss_cls: 0.01277  loss_box_reg: 0.03326  loss_mask: 0.05965  loss_rpn_cls: 0.000234  loss_rpn_loc: 0.002235  lr: 0.002  max_mem: 7203M
[07/26 17:21:10] d2.utils.events INFO:  eta: 0:01:28  iter: 7379  total_loss: 0.1076  loss_cls: 0.01288  loss_box_reg: 0.03286  loss_mask: 0.05906  loss_rpn_cls: 0.0002306  loss_rpn_loc: 0.002549  lr: 0.002  max_mem: 7203M
[07/26 17:21:25] d2.utils.events INFO:  eta: 0:01:14  iter: 7399  total_loss: 0.1087  loss_cls: 0.01323  loss_box_reg: 0.0329  loss_mask: 0.05937  loss_rpn_cls: 0.0001929  loss_rpn_loc: 0.002561  lr: 0.002  max_mem: 7203M
[07/26 17:21:40] d2.utils.events INFO:  eta: 0:00:59  iter: 7419  total_loss: 0.115  loss_cls: 0.01514  loss_box_reg: 0.0347  loss_mask: 0.06145  loss_rpn_cls: 0.0002915  loss_rpn_loc: 0.00288  lr: 0.002  max_mem: 7203M
[07/26 17:21:56] d2.utils.events INFO:  eta: 0:00:45  iter: 7439  total_loss: 0.1114  loss_cls: 0.01377  loss_box_reg: 0.03497  loss_mask: 0.05883  loss_rpn_cls: 0.0001989  loss_rpn_loc: 0.002605  lr: 0.002  max_mem: 7203M
[07/26 17:22:11] d2.utils.events INFO:  eta: 0:00:29  iter: 7459  total_loss: 0.1058  loss_cls: 0.01322  loss_box_reg: 0.03457  loss_mask: 0.05524  loss_rpn_cls: 0.0002138  loss_rpn_loc: 0.002658  lr: 0.002  max_mem: 7203M
[07/26 17:22:26] d2.utils.events INFO:  eta: 0:00:15  iter: 7479  total_loss: 0.1086  loss_cls: 0.01344  loss_box_reg: 0.0347  loss_mask: 0.05747  loss_rpn_cls: 0.0002156  loss_rpn_loc: 0.002556  lr: 0.002  max_mem: 7203M
[07/26 17:22:40] d2.utils.events INFO:  eta: 0:00:00  iter: 7499  total_loss: 0.1132  loss_cls: 0.0139  loss_box_reg: 0.03439  loss_mask: 0.0584  loss_rpn_cls: 0.0001801  loss_rpn_loc: 0.002652  lr: 0.002  max_mem: 7203M
[07/26 17:22:40] fvcore.common.checkpoint INFO: Saving checkpoint to output/with_augmentation/model_final.pth
[07/26 17:23:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[07/26 17:23:02] d2.data.common INFO: Serializing 45 elements to byte tensors and concatenating them all ...
[07/26 17:23:02] d2.data.common INFO: Serialized dataset takes 0.06 MiB
[07/26 17:23:02] d2.evaluation.evaluator INFO: Start inference on 45 batches
[07/26 17:23:03] d2.evaluation.evaluator INFO: Inference done 11/45. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.0003 s/iter. Total: 0.0571 s/iter. ETA=0:00:01
[07/26 17:23:05] d2.evaluation.evaluator INFO: Total inference time: 0:00:02.389537 (0.059738 s / iter per device, on 1 devices)
[07/26 17:23:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.056562 s / iter per device, on 1 devices)
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Saving results to output/with_augmentation/inference/for_detectron_synth_val/coco_instances_results.json
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.700 | 3.465  | 0.743  | 0.000 | 1.700 | 0.000 |
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 3.399 |
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[07/26 17:23:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.790 | 3.465  | 1.650  | 0.000 | 1.790 | 0.000 |
[07/26 17:23:05] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| Femur      | 0.000 | Tibia      | nan  | Guide      | 3.581 |
[07/26 17:23:05] detectron2 INFO: Evaluation results for for_detectron_synth_val in csv format:
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: 1.6997,3.4653,0.7426,0.0000,1.6997,0.0000
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: Task: segm
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/26 17:23:05] d2.evaluation.testing INFO: copypaste: 1.7904,3.4653,1.6502,0.0000,1.7904,0.0000
